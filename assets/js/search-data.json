{
  
    
        "post0": {
            "title": "Kaplan-Meier curve of overall survival of cases stratified by the mRNA level of a certain gene in an independent cohort",
            "content": "When dicovering genes and their function on deseases, survival curve is a good aspect to help us checking the influence of a factor (like genotype, RNA expression level, and age, gender). According to this pubilication here, &quot;the survival curve can be created assuming various situations. It involves computing of probabilities of occurrence of event at a certain point of time and multiplying these successive probabilities by any earlier computed probabilities to get the final estimate.&quot; . This note is about how I can make survival curve on a certain gene, and will keep it in update when I get new ideas later :) . Data source: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE53624 . Public microarray RNA expression data of ESCC were retrieved from GEO database (GSE53624). . # https://cran.r-project.org/web/packages/vroom/readme/README.html library(AnnoProbe) library(GEOquery) . Loading required package: Biobase Loading required package: BiocGenerics Attaching package: ‘BiocGenerics’ The following objects are masked from ‘package:stats’: IQR, mad, sd, var, xtabs The following objects are masked from ‘package:base’: anyDuplicated, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply, union, unique, unsplit, which.max, which.min Welcome to Bioconductor Vignettes contain introductory material; view with &#39;browseVignettes()&#39;. To cite Bioconductor, see &#39;citation(&#34;Biobase&#34;)&#39;, and for packages &#39;citation(&#34;pkgname&#34;)&#39;. Setting options(&#39;download.file.method.GEOquery&#39;=&#39;auto&#39;) Setting options(&#39;GEOquery.inmemory.gpl&#39;=FALSE) . setwd(&quot;~/Documents/notes/&quot;) . dir.create(&quot;GSE53624&quot;,recursive = T) eset &lt;- getGEO(&quot;GSE53624&quot;, destdir = &quot;./GSE53624&quot;, getGPL = F) . Found 1 file(s) GSE53624_series_matrix.txt.gz . expr &lt;- as.data.frame(exprs(eset[[1]])) head(expr[,1:4]) . A data.frame: 6 × 4 GSM1297076GSM1297077GSM1297078GSM1297079 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 114.196541 | 14.151714 | 13.796948 | 13.802610 | . 2 3.195847 | 3.042514 | 3.211573 | 2.995495 | . 2415.261637 | 15.830739 | 15.311610 | 15.527160 | . 25 3.157660 | 3.378073 | 3.165554 | 3.634285 | . 26 5.277165 | 5.297271 | 5.193853 | 5.467351 | . 27 8.545228 | 8.327291 | 8.527834 | 8.590668 | . Query probe annotation: . ids=idmap(&#39;GPL18109&#39;,&#39;pipe&#39;) head(ids) . file downloaded in /home/xiaofan/Documents/notes . A data.frame: 6 × 2 probe_idsymbol . &lt;int&gt;&lt;chr&gt; . 180108 | DDX11L1 | . 280108 | WASH7P | . 3 4320 | DDX11L1 | . 4 4320 | WASH7P | . 597414 | DDX11L1 | . 697414 | WASH7P | . Find the target gene: . ids[ids$symbol==&#39;CST1&#39;,] . A data.frame: 1 × 2 probe_idsymbol . &lt;int&gt;&lt;chr&gt; . 8029869686 | CST1 | . CST1 = expr[as.character(ids[ids$symbol==&#39;CST1&#39;,1]),] CST1 . A data.frame: 1 × 238 GSM1297076GSM1297077GSM1297078GSM1297079GSM1297080GSM1297081GSM1297082GSM1297083GSM1297084GSM1297085⋯GSM1297304GSM1297305GSM1297306GSM1297307GSM1297308GSM1297309GSM1297310GSM1297311GSM1297312GSM1297313 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;⋯&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 6968612.09817 | 8.922841 | 14.90663 | 10.18603 | 14.91623 | 10.18041 | 13.39866 | 9.199378 | 15.49725 | 11.30926 | ⋯ | 14.65862 | 9.33 | 13.42281 | 9.268775 | 13.32883 | 10.61139 | 11.57493 | 8.851528 | 13.1252 | 10.69054 | . CTSB = expr[as.character(ids[ids$symbol==&#39;CTSB&#39;,1]),] CTSB . A data.frame: 1 × 238 GSM1297076GSM1297077GSM1297078GSM1297079GSM1297080GSM1297081GSM1297082GSM1297083GSM1297084GSM1297085⋯GSM1297304GSM1297305GSM1297306GSM1297307GSM1297308GSM1297309GSM1297310GSM1297311GSM1297312GSM1297313 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;⋯&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 3125014.60582 | 13.59123 | 14.5945 | 14.11498 | 15.0071 | 13.28104 | 14.32997 | 13.90693 | 14.7381 | 14.59319 | ⋯ | 14.90712 | 14.35302 | 14.5781 | 14.20684 | 13.92457 | 13.75713 | 14.54719 | 14.45429 | 14.85223 | 14.14271 | . Metadata: GSE53624_clinical_data_of_patients_orignial_set.xls was downloaded from here . clinical &lt;- xlsx::read.xlsx(&quot;./GSE53624/GSE53624_clinical_data_of_patients_orignial_set.xlsx&quot;,sheetIndex = 1) . table(clinical$Death.at.FU) . no yes 46 73 . clinical$Death.at.FU &lt;- gsub(&quot;no&quot;,&quot;0&quot;, gsub(&quot;yes&quot;,&quot;1&quot;,clinical$Death.at.FU)) clinical_data &lt;- data.frame(OS.time=as.numeric(clinical$Survival.time.months.), OS=as.numeric(clinical$Death.at.FU), sample=clinical$Patient.ID) head(clinical_data) . A data.frame: 6 × 3 OS.timeOSsample . &lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt; . 148.766667 | 1 | ec4 | . 2 9.766667 | 1 | ec6 | . 3 5.833333 | 1 | ec7 | . 472.533333 | 0 | ec9 | . 572.633333 | 0 | ec10 | . 635.033333 | 1 | ec11 | . phenotype &lt;- pData(eset[[1]]) phe1 &lt;- data.frame(sample = rownames(phenotype), title = phenotype$title) phe1$tissue &lt;- stringr::str_split(phe1$title,&quot; &quot;,simplify = T)[,1] phe1$patient &lt;- stringr::str_split(phe1$title,&quot; &quot;,simplify = T)[,5] head(phe1) phe1=phe1[phe1$tissue == &#39;cancer&#39;,] phe1$patient=paste0(&#39;ec&#39;,phe1$patient) identical(phe1$patient,clinical_data$sample) . A data.frame: 6 × 4 sampletitletissuepatient . &lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt; . 1GSM1297076 | cancer tissue from patient 224 | cancer | 224 | . 2GSM1297077 | normal tissue from patient 224 | normal | 224 | . 3GSM1297078 | cancer tissue from patient 225 | cancer | 225 | . 4GSM1297079 | normal tissue from patient 225 | normal | 225 | . 5GSM1297080 | cancer tissue from patient 226 | cancer | 226 | . 6GSM1297081 | normal tissue from patient 226 | normal | 226 | . FALSE library(survival) . CST1.clinical_data=clinical_data[match(phe1$patient,clinical_data$sample),] CST1.cl=CST1[match(phe1$sample,colnames(expr))] CST1.cl . A data.frame: 1 × 119 GSM1297076GSM1297078GSM1297080GSM1297082GSM1297084GSM1297086GSM1297088GSM1297090GSM1297092GSM1297094⋯GSM1297294GSM1297296GSM1297298GSM1297300GSM1297302GSM1297304GSM1297306GSM1297308GSM1297310GSM1297312 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;⋯&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 6968612.09817 | 14.90663 | 14.91623 | 13.39866 | 15.49725 | 15.39298 | 14.39151 | 15.11474 | 15.29023 | 15.18338 | ⋯ | 12.50499 | 14.39441 | 10.29386 | 13.15363 | 12.39219 | 14.65862 | 13.42281 | 13.32883 | 11.57493 | 13.1252 | . CST1.cl=as.numeric(CST1.cl) CST1.clinical_data$gene = ifelse( CST1.cl &gt; median( CST1.cl ),&#39;high&#39;,&#39;low&#39;) head(CST1.clinical_data) . A data.frame: 6 × 4 OS.timeOSsamplegene . &lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt; . 6560.30000 | 0 | ec224 | low | . 6627.56667 | 1 | ec225 | high | . 6734.66667 | 1 | ec226 | high | . 6860.96667 | 0 | ec227 | low | . 8115.43333 | 1 | ec251 | high | . 8261.33333 | 0 | ec253 | high | . sfit1=survfit(Surv(OS.time, OS)~gene, data=CST1.clinical_data) p1 = survminer::ggsurvplot(sfit1,pval =TRUE, data = CST1.clinical_data, risk.table = TRUE) + ggplot2::labs(title=&quot;CST1&quot;) p1 . CTSB.clinical_data=clinical_data[match(phe1$patient,clinical_data$sample),] CTSB.cl=CTSB[match(phe1$sample,colnames(expr))] CTSB.cl=as.numeric(CTSB.cl) CTSB.clinical_data$gene = ifelse( CTSB.cl &gt; median( CTSB.cl ),&#39;high&#39;,&#39;low&#39;) sfit2=survfit(Surv(OS.time, OS)~gene, data=CTSB.clinical_data) p2 = survminer::ggsurvplot(sfit2,pval =TRUE, data = CTSB.clinical_data, risk.table = TRUE) + ggplot2::labs(title=&quot;CTSB&quot;) p2 . gene = &quot;TTF1&quot; ids[ids$symbol==&#39;TTF1&#39;,] . A data.frame: 3 × 2 probe_idsymbol . &lt;int&gt;&lt;chr&gt; . 44153 49101 | TTF1 | . 44154119532 | TTF1 | . 44155103167 | TTF1 | . TTF1 = expr[as.character(ids[ids$symbol==gene,1]),] TTF1 . A data.frame: 3 × 238 GSM1297076GSM1297077GSM1297078GSM1297079GSM1297080GSM1297081GSM1297082GSM1297083GSM1297084GSM1297085⋯GSM1297304GSM1297305GSM1297306GSM1297307GSM1297308GSM1297309GSM1297310GSM1297311GSM1297312GSM1297313 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;⋯&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 4910111.02987 | 10.80374 | 10.91583 | 10.62685 | 11.44957 | 10.91205 | 10.83738 | 10.77016 | 10.19814 | 10.18317 | ⋯ | 10.30097 | 10.15997 | 11.37990 | 10.83498 | 11.03148 | 10.65352 | 10.39791 | 10.39283 | 10.33114 | 9.444365 | . 11953211.71704 | 11.47166 | 11.61420 | 11.28658 | 12.13650 | 11.59252 | 11.56784 | 11.47886 | 11.26517 | 11.29613 | ⋯ | 11.07106 | 10.85781 | 11.89306 | 11.29598 | 11.60490 | 11.25663 | 11.00526 | 10.97788 | 10.99330 | 10.568630 | . 10316710.93233 | 10.77753 | 10.86874 | 10.84316 | 11.39397 | 10.94832 | 10.83884 | 10.89749 | 11.42119 | 11.34206 | ⋯ | 10.10479 | 10.09412 | 11.42420 | 10.70688 | 10.81011 | 10.55752 | 10.34643 | 10.31036 | 10.38547 | 9.385584 | . TTF1 = expr[49101,] TTF1 PTEN=TTF1 . A data.frame: 1 × 238 GSM1297076GSM1297077GSM1297078GSM1297079GSM1297080GSM1297081GSM1297082GSM1297083GSM1297084GSM1297085⋯GSM1297304GSM1297305GSM1297306GSM1297307GSM1297308GSM1297309GSM1297310GSM1297311GSM1297312GSM1297313 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;⋯&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 790666.391043 | 7.798494 | 5.072013 | 7.196961 | 6.798004 | 9.259991 | 5.799467 | 6.866773 | 3.912495 | 7.193734 | ⋯ | 7.867408 | 9.985494 | 4.70194 | 6.216463 | 4.815819 | 4.557891 | 5.632451 | 6.549177 | 4.005441 | 5.385023 | . TTF1.clinical_data=clinical_data[match(phe1$patient,clinical_data$sample),] TTF1.cl=as.numeric(TTF1[match(phe1$sample,colnames(expr))]) TTF1.clinical_data$gene = ifelse( TTF1.cl &gt; median( TTF1.cl ),&#39;high&#39;,&#39;low&#39;) sfit3=survfit(Surv(OS.time, OS)~gene, data=TTF1.clinical_data) survminer::ggsurvplot(sfit3,pval =TRUE, data = TTF1.clinical_data, risk.table = TRUE) + ggplot2::labs(title=&quot;TTF1&quot;) . sessionInfo() . R version 4.1.2 (2021-11-01) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux 10 (buster) Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=en_US.UTF-8 [9] LC_ADDRESS=en_US.UTF-8 LC_TELEPHONE=en_US.UTF-8 [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=en_US.UTF-8 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] survival_3.3-1 GEOquery_2.62.2 Biobase_2.54.0 [4] BiocGenerics_0.40.0 AnnoProbe_0.1.6 loaded via a namespace (and not attached): [1] ggtext_0.1.1 RColorBrewer_1.1-3 repr_1.1.4 tools_4.1.2 [5] backports_1.4.1 utf8_1.2.2 R6_2.5.1 DT_0.23 [9] DBI_1.1.2 colorspace_2.0-3 tidyselect_1.1.2 gridExtra_2.3 [13] curl_4.3.2 compiler_4.1.2 cli_3.3.0 Cairo_1.5-15 [17] xml2_1.3.3 labeling_0.4.2 scales_1.2.0 survMisc_0.5.6 [21] readr_2.1.2 pbdZMQ_0.3-7 stringr_1.4.0 digest_0.6.29 [25] R.utils_2.11.0 base64enc_0.1-3 pkgconfig_2.0.3 htmltools_0.5.2 [29] fastmap_1.1.0 limma_3.50.3 htmlwidgets_1.5.4 rlang_1.0.2 [33] generics_0.1.2 farver_2.1.0 zoo_1.8-10 jsonlite_1.8.0 [37] dplyr_1.0.9 xlsx_0.6.5 car_3.0-13 R.oo_1.24.0 [41] magrittr_2.0.3 Matrix_1.4-1 Rcpp_1.0.8.3 IRkernel_1.3 [45] munsell_0.5.0 fansi_1.0.3 abind_1.4-5 lifecycle_1.0.1 [49] R.methodsS3_1.8.1 stringi_1.7.6 carData_3.0-5 grid_4.1.2 [53] crayon_1.5.1 survminer_0.4.9 lattice_0.20-45 IRdisplay_1.1 [57] splines_4.1.2 gridtext_0.1.4 xlsxjars_0.6.1 hms_1.1.1 [61] knitr_1.39 pillar_1.7.0 ggpubr_0.4.0 uuid_1.1-0 [65] markdown_1.1 ggsignif_0.6.3 glue_1.6.2 evaluate_0.15 [69] data.table_1.14.2 vctrs_0.4.1 tzdb_0.3.0 gtable_0.3.0 [73] purrr_0.3.4 tidyr_1.2.0 km.ci_0.5-6 assertthat_0.2.1 [77] ggplot2_3.3.6 xfun_0.31 xtable_1.8-4 broom_0.8.0 [81] rstatix_0.7.0 tibble_3.1.7 pheatmap_1.0.12 rJava_1.0-6 [85] KMsurv_0.1-5 ellipsis_0.3.2 .",
            "url": "https://vikkki.github.io/vikkki_blog/r/jupyter/microarry/survival/2022/05/12/Survival_Curve_of_Gene.html",
            "relUrl": "/r/jupyter/microarry/survival/2022/05/12/Survival_Curve_of_Gene.html",
            "date": " • May 12, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "TCGA samples comparison on PCA plots",
            "content": "Inspired by one of the plots in this publication about urban/rural clovers, I was thinking if we can apply similar method to show some TCGA data, here is what I&#39;ve tried: . First, download count and metadata from UCSC Xena&amp;removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443): . proj &lt;- &quot;TCGA-CHOL&quot; header &lt;- &quot;https://gdc.xenahubs.net/download/&quot; . download.file(url = paste0(hearder ,proj, &quot;.htseq_counts.tsv.gz&quot;),destfile = paste0(proj,&quot;.htseq_counts.tsv.gz&quot;)) download.file(url = paste0(hearder ,proj, &quot;.GDC_phenotype.tsv.gz&quot;),destfile = paste0(proj,&quot;.GDC_phenotype.tsv.gz&quot;)) #download.file(url = paste0(hearder ,proj, &quot;.survival.tsv&quot;),destfile = paste0(proj,&quot;.survival.tsv&quot;)) . phenotype &lt;- read.delim(paste0(proj,&quot;.GDC_phenotype.tsv.gz&quot;),fill = T,header = T,sep = &quot; t&quot;) . Take a look at phenotype data: . phenotype[1:3,] . A data.frame: 3 × 122 submitter_id.samplesage_at_initial_pathologic_diagnosisalbumin_result_lower_limitalbumin_result_specified_valuealbumin_result_upper_limitbatch_numberbcrbcr_followup_barcodebcr_followup_uuidsubmitter_id⋯days_to_collection.samplesdays_to_sample_procurement.samplesinitial_weight.samplesis_ffpe.samplesoct_embedded.samplespreservation_method.samplessample_type.samplessample_type_id.samplesstate.samplestissue_type.samples . &lt;chr&gt;&lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;⋯&lt;dbl&gt;&lt;lgl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt;&lt;lgl&gt;&lt;chr&gt;&lt;int&gt;&lt;chr&gt;&lt;chr&gt; . 1TCGA-ZH-A8Y2-01A | 59 | NA | NA | NA | 428.25.0 | Nationwide Children&#39;s Hospital | | | TCGA-ZH-A8Y2 | ⋯ | 897 | NA | 400 | False | false | NA | Primary Tumor | 1 | released | Not Reported | . 2TCGA-ZH-A8Y7-01A | 59 | 3.5 | 2.4 | 5 | 448.13.0 | Nationwide Children&#39;s Hospital | | | TCGA-ZH-A8Y7 | ⋯ | 77 | NA | 1100 | False | false | NA | Primary Tumor | 1 | released | Not Reported | . 3TCGA-W7-A93O-01A | NA | NA | NA | NA | 448.13.0 | Nationwide Children&#39;s Hospital | | | TCGA-W7-A93O | ⋯ | 465 | NA | 180 | False | true | NA | Primary Tumor | 1 | released | Not Reported | . Load count matrix and convert it back from log . data &lt;- read.table(paste0(proj,&quot;.htseq_counts.tsv.gz&quot;),check.names = F,row.names = 1,header = T) data &lt;- as.data.frame(2^dat - 1) count &lt;- apply(dat, 2, as.integer) rownames(count) &lt;- rownames(data) . count[1:4,1:4] . A matrix: 4 × 4 of type int TCGA-ZD-A8I3-01ATCGA-W5-AA2U-11ATCGA-W5-AA30-01ATCGA-W5-AA38-01A . ENSG00000000003.135254 | 2476 | 5132 | 8249 | . ENSG00000000005.5 1 | 1 | 0 | 1 | . ENSG00000000419.111211 | 655 | 1643 | 1695 | . ENSG00000000457.12 752 | 345 | 2652 | 519 | . Then Filter out genes of which less than half samples have expression: . n_sample &lt;- ncol(count) n_sample count = count[apply(count, 1, function(x) sum(x &gt; 0) &gt; 0.5*n_sample), ] . 45 In sample Id we can extract its group info by checking the last 3 chars, like in TCGA-ZH-A8Y2-01A, 01A is tumor: . library(stringr) . Group = ifelse(as.numeric(str_sub(colnames(count),14,15)) &lt; 10,&#39;tumor&#39;,&#39;normal&#39;) Group = factor(Group,levels = c(&quot;normal&quot;,&quot;tumor&quot;)) table(Group) . Group normal tumor 9 36 . Normally we can use DESeq2, edgeR, or limma to move on to differential expression analysis, here we would jump over it for now and do PCA first. . library(ggplot2) library(tinyarray) . pca.plot = draw_pca(count,Group);pca.plot . Here it&#39;s clear that tumor and normal samples group in their own clusters, and we have CI as ovals surround each of them. Tumor cluster is larger and one of the cause could be heterogenesis; but before that we would noticed that tumor group has more samples than normal group. Next I&#39;m going to look at those samples that can be paired. .",
            "url": "https://vikkki.github.io/vikkki_blog/r/jupyter/pca/ggplot/tcga/2022/05/09/PCA_on_TCGA.html",
            "relUrl": "/r/jupyter/pca/ggplot/tcga/2022/05/09/PCA_on_TCGA.html",
            "date": " • May 9, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Ways to download fastq files of a GEO dataset",
            "content": "Ways to download fastq files of a GEO dataset . Download from NCBI . On the page of target dataset, here I’m trying to retrieve data from GEO Series Series GSE173771 here: . . . Below Supplementary fild section, click the link of “SRA Run Selector” to obtain accession list: . . Prefetch . “Prefetch is a part of the SRA toolkit. This program downloads Runs (sequence files in the compressed SRA format) and all additional data necessary to convert the Run from the SRA format to a more commonly used format. Prefetch can be used to correct and finish an incomplete Run download.” . For more info on prefetch and sra download, you can also refer to this page. . To install SRA toolkit of your system: https://github.com/ncbi/sra-tools/wiki/ . After setting up the toolkit, entire target folder: . cd ./data_path_to_download_into/ # make command list: cat ../SRR_Acc_List.txt | while read id do echo prefetch ${id} -O ./ done &gt; prefetch.command # take a look cat prefetch.command # run downloading nohup bash prefetch.command &amp; . Format convert . mkdir fastq cd fastq ln -s ~/path/to/1.sra_data/* ./fastq/ cat ../SRR_Acc_List.txt | while read id do # fasterq-dump is also part of src-toolkit echo &quot;fasterq-dump -e 32 --split-files -O ./ --outfile ${id}.fastq ../sra/${id}.sra&quot; echo &quot;pigz -p 16 -f ./${id}_1.fastq&quot; echo &quot;pigz -p 16 -f ./${id}_2.fastq&quot; done &gt; sra2fq.sh cat sra2fq.sh nohup bash sra2fq.sh &amp; . Or, it could be another option to download data (fastq) from EMBL-EBI: . Generate download path: . On ENA homepage: https://www.ebi.ac.uk/ena/browser/home search for GSE173771: . https://www.ebi.ac.uk/ena/browser/view/PRJNA726999?show=reads . We can download fastq files directly, or with Aspera, use command line to download them. . . Created at 03/21/2022, editted at 5/10/2022 by vikkki 🌲 .",
            "url": "https://vikkki.github.io/vikkki_blog/fastq/geo/downloading/prefetch/2022/03/21/Download-fatsq.html",
            "relUrl": "/fastq/geo/downloading/prefetch/2022/03/21/Download-fatsq.html",
            "date": " • Mar 21, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Cell-Cycle Scoring with Seurat and ggplot2",
            "content": "This note uses R kernel. . First load the data matrix, the files used are available from here. . library(Seurat) # Read in the expression matrix The first row is a header row, the first column is rownames exp.mat &lt;- read.table(file = &quot;./nestorawa_forcellcycle_expressionMatrix.txt&quot;, header = TRUE, as.is = TRUE, row.names = 1) # A list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat. We can # segregate this list into markers of G2/M phase and markers of S phase s.genes &lt;- cc.genes$s.genes g2m.genes &lt;- cc.genes$g2m.genes # Create our Seurat object and complete the initalization steps marrow &lt;- CreateSeuratObject(counts = exp.mat) marrow &lt;- NormalizeData(marrow) marrow &lt;- FindVariableFeatures(marrow, selection.method = &quot;vst&quot;) marrow &lt;- ScaleData(marrow, features = rownames(marrow)) . Registered S3 method overwritten by &#39;spatstat.geom&#39;: method from print.boxx cli Attaching SeuratObject Centering and scaling data matrix . If we run a PCA on our object, using the variable genes we found in FindVariableFeatures() above, we see that while most of the variance can be explained by lineage, PC8 and PC10 are split on cell-cycle genes including TOP2A and MKI67. We will attempt to regress this signal from the data, so that cell-cycle heterogeneity does not contribute to PCA or downstream analysis. . marrow &lt;- RunPCA(marrow, features = VariableFeatures(marrow), ndims.print = 6:10, nfeatures.print = 10) . PC_ 6 Positive: SELL, ARL6IP1, CCL9, CD34, ADGRL4, BPIFC, NUSAP1, FAM64A, CD244, C030034L19RIK Negative: LY6C2, AA467197, CYBB, MGST2, ITGB2, PF4, CD74, ATP1B1, GP1BB, TREM3 PC_ 7 Positive: F13A1, LY86, CFP, IRF8, CSF1R, TIFAB, IFI209, CCR2, TNS4, MS4A6C Negative: HDC, CPA3, PGLYRP1, MS4A3, NKG7, UBE2C, CCNB1, NUSAP1, PLK1, FUT8 PC_ 8 Positive: NUSAP1, UBE2C, KIF23, PLK1, CENPF, FAM64A, CCNB1, H2AFX, ID2, CDC20 Negative: WFDC17, SLC35D3, ADGRL4, VLDLR, CD33, H2AFY, P2RY14, IFI206, CCL9, CD34 PC_ 9 Positive: IGKC, JCHAIN, LY6D, MZB1, CD74, IGLC2, FCRLA, IGKV4-50, IGHM, IGHV9-1 Negative: SLC2A6, HBA-A1, HBA-A2, IGHV8-7, FCER1G, F13A1, HBB-BS, PLD4, HBB-BT, IGFBP4 PC_ 10 Positive: H2AFX, FAM64A, ZFP383, NUSAP1, CDC25B, CENPF, GBP10, TOP2A, GBP6, GFRA1 Negative: CTSW, XKRX, PRR5L, RORA, MBOAT4, A630014C17RIK, ZFP105, COL9A3, CLEC2I, TRAT1 . DimHeatmap(marrow, dims = c(8, 10)) . Assign Cell-Cycle Scores . In the CellCycleScoring() function, which stores S and G2/M scores in object meta data, along with the predicted classification of each cell in either G2M, S or G1 phase. . marrow &lt;- CellCycleScoring(marrow, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE) # view cell cycle scores and phase assignments head(marrow[[]]) . Warning message: “The following features are not present in the object: MLF1IP, GMNN, not searching for symbol synonyms” . A data.frame: 6 × 7 orig.identnCount_RNAnFeature_RNAS.ScoreG2M.ScorePhaseold.ident . &lt;fct&gt;&lt;dbl&gt;&lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;fct&gt; . Prog_013Prog | 2563089 | 10211 | -0.14248691 | -0.4680395 | G1 | Prog | . Prog_019Prog | 3030620 | 9991 | -0.16915786 | 0.5851766 | G2M | Prog | . Prog_031Prog | 1293487 | 10192 | -0.34627038 | -0.3971879 | G1 | Prog | . Prog_037Prog | 1357987 | 9599 | -0.44270212 | 0.6820229 | G2M | Prog | . Prog_008Prog | 4079891 | 10540 | 0.55854051 | 0.1284359 | S | Prog | . Prog_014Prog | 2569783 | 10788 | 0.07116218 | 0.3166073 | G2M | Prog | . RidgePlot(marrow, features = c(&quot;PCNA&quot;, &quot;TOP2A&quot;, &quot;MCM6&quot;, &quot;MKI67&quot;), ncol = 2) . Picking joint bandwidth of 0.144 Picking joint bandwidth of 0.143 Picking joint bandwidth of 0.177 Picking joint bandwidth of 0.129 . s.genes . &lt;ol class=list-inline&gt;&#39;MCM5&#39; | &#39;PCNA&#39; | &#39;TYMS&#39; | &#39;FEN1&#39; | &#39;MCM2&#39; | &#39;MCM4&#39; | &#39;RRM1&#39; | &#39;UNG&#39; | &#39;GINS2&#39; | &#39;MCM6&#39; | &#39;CDCA7&#39; | &#39;DTL&#39; | &#39;PRIM1&#39; | &#39;UHRF1&#39; | &#39;MLF1IP&#39; | &#39;HELLS&#39; | &#39;RFC2&#39; | &#39;RPA2&#39; | &#39;NASP&#39; | &#39;RAD51AP1&#39; | &#39;GMNN&#39; | &#39;WDR76&#39; | &#39;SLBP&#39; | &#39;CCNE2&#39; | &#39;UBR7&#39; | &#39;POLD3&#39; | &#39;MSH2&#39; | &#39;ATAD2&#39; | &#39;RAD51&#39; | &#39;RRM2&#39; | &#39;CDC45&#39; | &#39;CDC6&#39; | &#39;EXO1&#39; | &#39;TIPIN&#39; | &#39;DSCC1&#39; | &#39;BLM&#39; | &#39;CASP8AP2&#39; | &#39;USP1&#39; | &#39;CLSPN&#39; | &#39;POLA1&#39; | &#39;CHAF1B&#39; | &#39;BRIP1&#39; | &#39;E2F8&#39; | &lt;/ol&gt; g2m.genes . &lt;ol class=list-inline&gt;&#39;HMGB2&#39; | &#39;CDK1&#39; | &#39;NUSAP1&#39; | &#39;UBE2C&#39; | &#39;BIRC5&#39; | &#39;TPX2&#39; | &#39;TOP2A&#39; | &#39;NDC80&#39; | &#39;CKS2&#39; | &#39;NUF2&#39; | &#39;CKS1B&#39; | &#39;MKI67&#39; | &#39;TMPO&#39; | &#39;CENPF&#39; | &#39;TACC3&#39; | &#39;FAM64A&#39; | &#39;SMC4&#39; | &#39;CCNB2&#39; | &#39;CKAP2L&#39; | &#39;CKAP2&#39; | &#39;AURKB&#39; | &#39;BUB1&#39; | &#39;KIF11&#39; | &#39;ANP32E&#39; | &#39;TUBB4B&#39; | &#39;GTSE1&#39; | &#39;KIF20B&#39; | &#39;HJURP&#39; | &#39;CDCA3&#39; | &#39;HN1&#39; | &#39;CDC20&#39; | &#39;TTK&#39; | &#39;CDC25C&#39; | &#39;KIF2C&#39; | &#39;RANGAP1&#39; | &#39;NCAPD2&#39; | &#39;DLGAP5&#39; | &#39;CDCA2&#39; | &#39;CDCA8&#39; | &#39;ECT2&#39; | &#39;KIF23&#39; | &#39;HMMR&#39; | &#39;AURKA&#39; | &#39;PSRC1&#39; | &#39;ANLN&#39; | &#39;LBR&#39; | &#39;CKAP5&#39; | &#39;CENPE&#39; | &#39;CTCF&#39; | &#39;NEK2&#39; | &#39;G2E3&#39; | &#39;GAS2L3&#39; | &#39;CBX5&#39; | &#39;CENPA&#39; | &lt;/ol&gt; For more information about how to regress this source of heterogeneity(cell cycles) out of the data, you can check here. . Check clusters and identify cells . Number of clusters could be adjust based on the background information. . marrow &lt;- FindNeighbors(marrow, dims = 1:10) marrow &lt;- FindClusters(marrow, resolution = 0.5) . Computing nearest neighbor graph Computing SNN . Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck Number of nodes: 774 Number of edges: 21265 Running Louvain algorithm... Maximum modularity in 10 random starts: 0.8447 Number of communities: 6 Elapsed time: 0 seconds . head(Idents(marrow), 5) . &lt;dl class=dl-inline&gt;Prog_0130Prog_0190Prog_0313Prog_0375Prog_0081&lt;/dl&gt; &lt;summary style=display:list-item;cursor:pointer&gt; Levels: &lt;/summary&gt; &lt;ol class=list-inline&gt;&#39;0&#39; | &#39;1&#39; | &#39;2&#39; | &#39;3&#39; | &#39;4&#39; | &#39;5&#39; | &lt;/ol&gt; Run umap and visualize: . marrow &lt;- RunUMAP(marrow, dims = 1:10, verbose = FALSE) DimPlot(marrow, reduction = &quot;umap&quot;, label = TRUE) . Warning message: “The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric To use Python UMAP via reticulate, set umap.method to &#39;umap-learn&#39; and metric to &#39;correlation&#39; This message will be shown once per session” . Annotation with SingleR . library(celldex, verbose = FALSE) hpca.se &lt;- HumanPrimaryCellAtlasData() . Loading required package: SummarizedExperiment Loading required package: MatrixGenerics Loading required package: matrixStats Attaching package: ‘MatrixGenerics’ The following objects are masked from ‘package:matrixStats’: colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse, colCounts, colCummaxs, colCummins, colCumprods, colCumsums, colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs, colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats, colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds, colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads, colWeightedMeans, colWeightedMedians, colWeightedSds, colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet, rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods, rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps, rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins, rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks, rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars, rowWeightedMads, rowWeightedMeans, rowWeightedMedians, rowWeightedSds, rowWeightedVars Loading required package: GenomicRanges Loading required package: stats4 Loading required package: BiocGenerics Attaching package: ‘BiocGenerics’ The following objects are masked from ‘package:stats’: IQR, mad, sd, var, xtabs The following objects are masked from ‘package:base’: anyDuplicated, append, as.data.frame, basename, cbind, colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply, union, unique, unsplit, which.max, which.min Loading required package: S4Vectors Attaching package: ‘S4Vectors’ The following objects are masked from ‘package:base’: expand.grid, I, unname Loading required package: IRanges Loading required package: GenomeInfoDb Loading required package: Biobase Welcome to Bioconductor Vignettes contain introductory material; view with &#39;browseVignettes()&#39;. To cite Bioconductor, see &#39;citation(&#34;Biobase&#34;)&#39;, and for packages &#39;citation(&#34;pkgname&#34;)&#39;. Attaching package: ‘Biobase’ The following object is masked from ‘package:MatrixGenerics’: rowMedians The following objects are masked from ‘package:matrixStats’: anyMissing, rowMedians Attaching package: ‘SummarizedExperiment’ The following object is masked from ‘package:SeuratObject’: Assays The following object is masked from ‘package:Seurat’: Assays snapshotDate(): 2021-10-19 see ?celldex and browseVignettes(&#39;celldex&#39;) for documentation loading from cache see ?celldex and browseVignettes(&#39;celldex&#39;) for documentation loading from cache . hpca.se . class: SummarizedExperiment dim: 19363 713 metadata(0): assays(1): logcounts rownames(19363): A1BG A1BG-AS1 ... ZZEF1 ZZZ3 rowData names(0): colnames(713): GSM112490 GSM112491 ... GSM92233 GSM92234 colData names(3): label.main label.fine label.ont . pred.hesc &lt;- SingleR::SingleR(GetAssayData(marrow, assay = &quot;RNA&quot;, slot = &quot;data&quot;), clusters = Idents(marrow),ref = hpca.se, assay.type.test=1, labels = hpca.se$label.main) . pred.hesc . DataFrame with 6 rows and 5 columns scores first.labels tuning.scores labels &lt;matrix&gt; &lt;character&gt; &lt;DataFrame&gt; &lt;character&gt; 0 0.377020:0.586039:0.612565:... GMP 0.358065:0.267735 GMP 1 0.420151:0.546801:0.551765:... MEP 0.412205:0.353706 Erythroblast 2 0.401024:0.572664:0.578866:... MEP 0.273437:0.226113 MEP 3 0.378935:0.548739:0.578182:... CMP 0.224248:0.218487 CMP 4 0.375977:0.579766:0.627907:... GMP 0.246549:0.214529 Pro-Myelocyte 5 0.392911:0.556911:0.582148:... MEP 0.251734:0.186742 MEP pruned.labels &lt;character&gt; 0 GMP 1 Erythroblast 2 MEP 3 CMP 4 Pro-Myelocyte 5 MEP . table(pred.hesc$labels) . CMP Erythroblast GMP MEP Pro-Myelocyte 1 1 1 2 1 . Import cluster ident information back to seurat object. . marrow[[&quot;SingleR.cluster.labels&quot;]] &lt;- pred.hesc$labels[match(Idents(marrow), rownames(pred.hesc))] . DimPlot(marrow, reduction = &quot;umap&quot;, label = TRUE,group.by = &quot;SingleR.cluster.labels&quot;) . Or identify cells individually: . pred.hesc2 &lt;- SingleR::SingleR(GetAssayData(marrow, assay = &quot;RNA&quot;, slot = &quot;data&quot;),ref = hpca.se, assay.type.test=1, labels = hpca.se$label.main) table(pred.hesc2$labels) . B_cell BM &amp; Prog. CMP Erythroblast 1 13 168 177 GMP HSC_-G-CSF MEP Pro-B_cell_CD34+ 184 1 169 14 Pro-Myelocyte 47 . colors = c(&quot;#097559&quot;,&quot;#757575&quot;,&quot;#C29359&quot;,&quot;#C2101E&quot;,&quot;#EDDB51&quot;,&quot;#EDDCBE&quot;,&quot;#F7A3AA&quot;,&quot;#1BBCC2&quot;,&quot;#F6E246&quot;) marrow[[&quot;SingleR.labels&quot;]] &lt;- pred.hesc2$labels DimPlot(marrow, reduction = &quot;umap&quot;, label = TRUE,group.by = &quot;SingleR.labels&quot;) . Re-plot with ggplot2 . Here to demostrate both the cell cyclcing information and cell definistion from SingleR, shapes and color are used to represent different layers of data. . colors = c(&quot;#097559&quot;,&quot;#757575&quot;,&quot;#C29359&quot;,&quot;#C2101E&quot;,&quot;#EDDB51&quot;,&quot;#EDDCBE&quot;,&quot;#F7A3AA&quot;,&quot;#1BBCC2&quot;,&quot;#F6E246&quot;) DimPlot(marrow, reduction = &quot;umap&quot;, label = TRUE, group.by = &quot;SingleR.labels&quot;, cols = colors) . Export to use ggplot2 directly: . library(tidyverse, verbose = FALSE) . ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ✔ tibble 3.1.6 ✔ dplyr 1.0.8 ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ✔ readr 2.1.2 ✔ forcats 0.5.1 ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::collapse() masks IRanges::collapse() ✖ dplyr::combine() masks Biobase::combine(), BiocGenerics::combine() ✖ dplyr::count() masks matrixStats::count() ✖ dplyr::desc() masks IRanges::desc() ✖ tidyr::expand() masks S4Vectors::expand() ✖ dplyr::filter() masks stats::filter() ✖ dplyr::first() masks S4Vectors::first() ✖ dplyr::lag() masks stats::lag() ✖ ggplot2::Position() masks BiocGenerics::Position(), base::Position() ✖ purrr::reduce() masks GenomicRanges::reduce(), IRanges::reduce() ✖ dplyr::rename() masks S4Vectors::rename() ✖ dplyr::slice() masks IRanges::slice() . umap_tx = marrow@reductions$umap@cell.embeddings %&gt;% as.data.frame() %&gt;% cbind(cycle = marrow@meta.data$Phase) %&gt;% cbind(singleRid = marrow@meta.data$SingleR.labels) . options(repr.plot.width=12, repr.plot.height=8) . ggplot(umap_tx, aes(x=UMAP_1, y=UMAP_2, color=singleRid, shape=cycle)) + geom_point(aes(size=cycle), alpha = 0.6 ) + scale_color_manual(values = colors) + scale_size_manual(values = c(6,3,3)) + scale_shape_manual(values = c(16,17,18)) + theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) . We can tall from the plot that cell cycling phases could contribute to the ambiguity of annotation and clustering. . Session information . sessionInfo() . R version 4.1.2 (2021-11-01) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux 11 (bullseye) Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0 LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] forcats_0.5.1 stringr_1.4.0 [3] dplyr_1.0.8 purrr_0.3.4 [5] readr_2.1.2 tidyr_1.2.0 [7] tibble_3.1.6 ggplot2_3.3.5 [9] tidyverse_1.3.1 celldex_1.4.0 [11] SummarizedExperiment_1.24.0 Biobase_2.54.0 [13] GenomicRanges_1.46.1 GenomeInfoDb_1.30.1 [15] IRanges_2.28.0 S4Vectors_0.32.3 [17] BiocGenerics_0.40.0 MatrixGenerics_1.6.0 [19] matrixStats_0.61.0 SeuratObject_4.0.4 [21] Seurat_4.1.0 loaded via a namespace (and not attached): [1] utf8_1.2.2 reticulate_1.24 [3] tidyselect_1.1.1 RSQLite_2.2.9 [5] AnnotationDbi_1.56.2 htmlwidgets_1.5.4 [7] grid_4.1.2 BiocParallel_1.28.3 [9] Rtsne_0.15 munsell_0.5.0 [11] ScaledMatrix_1.2.0 codetools_0.2-18 [13] ica_1.0-2 pbdZMQ_0.3-7 [15] future_1.23.0 miniUI_0.1.1.1 [17] withr_2.4.3 colorspace_2.0-2 [19] filelock_1.0.2 uuid_1.0-3 [21] rstudioapi_0.13 ROCR_1.0-11 [23] tensor_1.5 listenv_0.8.0 [25] labeling_0.4.2 repr_1.1.4 [27] GenomeInfoDbData_1.2.7 polyclip_1.10-0 [29] bit64_4.0.5 farver_2.1.0 [31] parallelly_1.30.0 vctrs_0.3.8 [33] generics_0.1.2 BiocFileCache_2.2.1 [35] R6_2.5.1 rsvd_1.0.5 [37] bitops_1.0-7 spatstat.utils_2.3-0 [39] cachem_1.0.6 DelayedArray_0.20.0 [41] assertthat_0.2.1 promises_1.2.0.1 [43] scales_1.1.1 gtable_0.3.0 [45] beachmat_2.10.0 globals_0.14.0 [47] goftest_1.2-3 rlang_1.0.1 [49] splines_4.1.2 lazyeval_0.2.2 [51] spatstat.geom_2.3-1 broom_0.7.12 [53] BiocManager_1.30.16 yaml_2.2.2 [55] reshape2_1.4.4 abind_1.4-5 [57] modelr_0.1.8 backports_1.4.1 [59] httpuv_1.6.5 tools_4.1.2 [61] ellipsis_0.3.2 spatstat.core_2.3-2 [63] RColorBrewer_1.1-2 ggridges_0.5.3 [65] Rcpp_1.0.8 plyr_1.8.6 [67] base64enc_0.1-3 sparseMatrixStats_1.6.0 [69] zlibbioc_1.40.0 RCurl_1.98-1.6 [71] rpart_4.1.16 deldir_1.0-6 [73] pbapply_1.5-0 cowplot_1.1.1 [75] zoo_1.8-9 haven_2.4.3 [77] ggrepel_0.9.1 cluster_2.1.2 [79] fs_1.5.2 magrittr_2.0.2 [81] data.table_1.14.2 RSpectra_0.16-0 [83] scattermore_0.7 reprex_2.0.1 [85] lmtest_0.9-39 RANN_2.6.1 [87] fitdistrplus_1.1-6 hms_1.1.1 [89] patchwork_1.1.1 mime_0.12 [91] evaluate_0.14 xtable_1.8-4 [93] readxl_1.3.1 gridExtra_2.3 [95] compiler_4.1.2 KernSmooth_2.23-20 [97] crayon_1.4.2 htmltools_0.5.2 [99] tzdb_0.2.0 mgcv_1.8-38 [101] later_1.3.0 lubridate_1.8.0 [103] DBI_1.1.2 ExperimentHub_2.2.1 [105] dbplyr_2.1.1 MASS_7.3-55 [107] rappdirs_0.3.3 Matrix_1.4-0 [109] cli_3.1.1 parallel_4.1.2 [111] igraph_1.2.11 pkgconfig_2.0.3 [113] IRdisplay_1.1 plotly_4.10.0 [115] spatstat.sparse_2.1-0 xml2_1.3.3 [117] XVector_0.34.0 rvest_1.0.2 [119] digest_0.6.29 sctransform_0.3.3 [121] RcppAnnoy_0.0.19 SingleR_1.8.1 [123] spatstat.data_2.1-2 Biostrings_2.62.0 [125] cellranger_1.1.0 leiden_0.3.9 [127] uwot_0.1.11 DelayedMatrixStats_1.16.0 [129] curl_4.3.2 shiny_1.7.1 [131] lifecycle_1.0.1 nlme_3.1-155 [133] jsonlite_1.7.3 BiocNeighbors_1.12.0 [135] viridisLite_0.4.0 fansi_1.0.2 [137] pillar_1.7.0 lattice_0.20-45 [139] KEGGREST_1.34.0 fastmap_1.1.0 [141] httr_1.4.2 survival_3.2-13 [143] interactiveDisplayBase_1.32.0 glue_1.6.1 [145] png_0.1-7 BiocVersion_3.14.0 [147] bit_4.0.4 stringi_1.7.6 [149] blob_1.2.2 BiocSingular_1.10.0 [151] AnnotationHub_3.2.1 memoise_2.0.1 [153] IRkernel_1.3.0.9000 irlba_2.3.5 [155] future.apply_1.8.1 . Created: 02/09/2022 by vikkki .",
            "url": "https://vikkki.github.io/vikkki_blog/r/jupyter/singlecell/seurat/ggplot/2022/02/09/CellCycle-and-SingleR.html",
            "relUrl": "/r/jupyter/singlecell/seurat/ggplot/2022/02/09/CellCycle-and-SingleR.html",
            "date": " • Feb 9, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Automated_Cell_Annotation",
            "content": "This notebook allows you to annotate your data with a number of annotation methods using the Tabula Sapiens dataset as the reference. . Initial setup: . Make sure GPU is enabled (Runtime -&gt; Change Runtime Type -&gt; Hardware Accelerator -&gt; GPU) | We also highly recommend getting Colab PRO for access to a high ram session. | Integration Methods Provided: . scVI | bbKNN | scanorama | . Annotation Methods: . KNN on integrated spaces | scANVI | onClass | SVM | RandomForest | . To use the notebook, simply connect to your Google Drive account, set the necessary arguments, select your methods, and run all the code blocks! . *User action is only required in Step 2 and Step 3. . Step 1: Setup Environment . No user input required here. . %%capture #@title Setup Colab #@markdown Here we install the necessary packages #@markdown This will take a few minutes (~5 min) import sys import os !pip install --quiet obonet !pip install --quiet --upgrade jsonschema !pip install --quiet bbknn !pip install --quiet git+https://github.com/wangshenguiuc/OnClass@21232f293a549a7ee0da8ebe3cbb22df3e885d4c !pip install --quiet git+https://github.com/yoseflab/scvi-tools@master#egg=scvi-tools[tutorials] !pip install --quiet imgkit !pip install --quiet gdown !pip install --quiet --upgrade scanorama # Download annoation code !wget -O annotation.py -q https://www.dropbox.com/s/id8sallwrunjc5c/annotation.py?dl=1 . import anndata import numpy as np import scanpy as sc import scvi . Step 2: Load your data (User Action Required) . Here we provide three options to load your data: . Connect to Google Drive (highly recommended) | Download your data from the cloud and save into this session or on Google drive. | Upload your data manually into this session (files are not persistent and will be deleted when session is closed) | As an example, we use a subsampled version of the Lung Cell Atlas [1] for our query data. . [1] Travaglini, K. et al. A molecular cell atlas of the human lung from single-cell RNA sequencing. Nature 587, 619–625(2020). . # This is the recomended method especially for large datasets from google.colab import drive drive.mount(&#39;/content/drive&#39;) query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . # Google Colab supports wget, curl, and gdown commands # It is recommended to download the data into Google Drive and read from there. # This way your data will be persistent. !wget &lt;YOUR URL&gt; query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . # Click the folder icon on the left navigation bar, and select the upload icon # Note: Manually uploaded data is automatically deleted when the colab session ends # This is not recommended if your dataset is very large query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . !wget -O LCA.h5ad https://www.dropbox.com/s/mrf8y7emfupo4he/LCA.h5ad?dl=1 query_adata = anndata.read(&#39;LCA.h5ad&#39;) . query_adata . AnnData object with n_obs × n_vars = 75071 × 23681 obs: &#39;method&#39;, &#39;donor&#39;, &#39;cell_ontology_type&#39;, &#39;donor_method&#39;, &#39;cell_ontology_id&#39; . Check that query_adata.X contains raw_counts . from annotation import _check_nonnegative_integers assert _check_nonnegative_integers(query_adata.X) == True, &#39;Make sure query_adata.X contains raw_counts&#39; . Step 3: Setting Up Annotation Parameters (User Action Required) . Here is where you set the parameters for the automated annotation. . Arguments: . tissue: Tabula Sapiens tissue to annotate your data with. Available tissues: [&quot;Bladder&quot;, &quot;Blood&quot;, &quot;Bone_Marrow&quot;, &quot;Kidney&quot;, &quot;Large_Intestine&quot;, &quot;Lung&quot;,&quot;Lymph_Node&quot;, &quot;Pancreas&quot;, &quot;Small_Intestine&quot;, &quot;Spleen&quot;, &quot;Thymus&quot;,&quot;Trachea&quot;, &quot;Vasculature&quot;] | save_location: location to save results to. By default will save to a folder named annotation_results. It is highly recommended you provide a Google Drive folder here. | query_batch_key: key in query_adata.obs for batch correction. Set to None for no batch correction. | methods: these are the methods to run. By default, will run all methods. | training_mode can be online or offline. If offline will train scVI and scANVI models from scratch. If online, will use pretrained models. | . Lesser used parameters . query_labels_key: scANVI has the option to use labeled cells in the query dataset during training. To use some prelabeled cells from the query dataset, set query_labels_key to the corresponding key in query_adata.obs | unknown_celltype_label: If query_labels_key is not None, will treat everything not labeled unknown_celltype_label as a labeled cell | . &quot;&quot;&quot; tissue options: [&quot;Bladder&quot;, &quot;Blood&quot;, &quot;Bone_Marrow&quot;, &quot;Kidney&quot;, &quot;Large_Intestine&quot;, &quot;Lung&quot;, &quot;Lymph_Node&quot;, &quot;Pancreas&quot;, &quot;Small_Intestine&quot;, &quot;Spleen&quot;, &quot;Thymus&quot;, &quot;Trachea&quot;, &quot;Vasculature&quot;] &quot;&quot;&quot; tissue = &#39;Lung&#39; save_folder = &#39;./&#39; query_batch_key = &#39;method&#39; methods = [&#39;bbknn&#39;,&#39;scvi&#39;, &#39;scanvi&#39;, &#39;svm&#39;, &#39;rf&#39;, &#39;onclass&#39;, &#39;scanorama&#39;] training_mode=&#39;online&#39; # Lesser used parameters query_labels_key=None unknown_celltype_label=&#39;unknown&#39; . Step 4: Downloading Reference Data and Pretrained Models . No more user input required! Just run all the following code blocks. . if tissue == &#39;Bladder&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388874&#39; pretrained_url=&#39;https://www.dropbox.com/s/rb89y577l6vs2mm/Bladder.tar.gz?dl=1&#39; elif tissue == &#39;Blood&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388853&#39; pretrained_url = &#39;https://www.dropbox.com/s/kyh9nv202n0db65/Blood.tar.gz?dl=1&#39; elif tissue == &#39;Bone_Marrow&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388841&#39; pretrained_url = &#39;https://www.dropbox.com/s/a3r4ddg7o7kua7z/Bone_Marrow.tar.gz?dl=1&#39; elif tissue == &#39;Kidney&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388838&#39; pretrained_url = &#39;https://www.dropbox.com/s/k41r1a346z0tuip/Kidney.tar.gz?dl=1&#39; elif tissue == &#39;Large_Intestine&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388835&#39; pretrained_url = &#39;https://www.dropbox.com/s/jwvpk727hd54byd/Large_Intestine.tar.gz?dl=1&#39; elif tissue == &#39;Lung&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388832&#39; pretrained_url = &#39;https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1&#39; elif tissue == &#39;Lymph_Node&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388715&#39; pretrained_url = &#39;https://www.dropbox.com/s/mbejy9tcbx9e1yv/Lymph_Node.tar.gz?dl=1&#39; elif tissue == &#39;Pancreas&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388613&#39; pretrained_url = &#39;https://www.dropbox.com/s/r3klvr22m6kq143/Pancreas.tar.gz?dl=1&#39; elif tissue == &#39;Small_Intestine&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388559&#39; pretrained_url = &#39;https://www.dropbox.com/s/7eiv2mke70jinzc/Small_Intestine.tar.gz?dl=1&#39; elif tissue == &#39;Spleen&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388544&#39; pretrained_url = &#39;https://www.dropbox.com/s/6j3iwahsjnb8rb3/Spleen.tar.gz?dl=1&#39; elif tissue == &#39;Thymus&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388505&#39; pretrained_url=&#39;https://www.dropbox.com/s/9k0mneu2wvpiudz/Thymus.tar.gz?dl=1&#39; elif tissue == &#39;Trachea&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388460&#39; pretrained_url = &#39;https://www.dropbox.com/s/57tthfgkl8jtxk6/Trachea.tar.gz?dl=1&#39; elif tissue == &#39;Vasculature&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388451&#39; pretrained_url=&#39;https://www.dropbox.com/s/1wt3r871kxjas5o/Vasculature.tar.gz?dl=1&#39; # Download reference dataset output_fn = &#39;TS_{}.h5ad&#39;.format(tissue) !wget -O $output_fn $refdata_url # Download pretrained scVI and scANVI models. output_fn = &#39;{}.tar.gz&#39;.format(tissue) !wget -O $output_fn $pretrained_url !tar -xvzf $output_fn # Download onclass files !wget -O cl.obo -q https://www.dropbox.com/s/hodp0etapzrd8ak/cl.obo?dl=1 !wget -O cl.ontology -q https://www.dropbox.com/s/nes0zprzfbwbgj5/cl.ontology?dl=1 !wget -O cl.ontology.nlp.emb https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1 . --2021-05-25 16:09:11-- https://ndownloader.figshare.com/files/27388832 Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 18.202.93.19, 3.248.64.20, 34.249.85.89, ... Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|18.202.93.19|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2673660872 (2.5G) [application/octet-stream] Saving to: ‘TS_Lung.h5ad’ TS_Lung.h5ad 100%[===================&gt;] 2.49G 20.3MB/s in 2m 23s 2021-05-25 16:11:35 (17.8 MB/s) - ‘TS_Lung.h5ad’ saved [2673660872/2673660872] --2021-05-25 16:11:35-- https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1 Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112 Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: /s/dl/e4al4ia9hm9qtcg/Lung.tar.gz [following] --2021-05-25 16:11:36-- https://www.dropbox.com/s/dl/e4al4ia9hm9qtcg/Lung.tar.gz Reusing existing connection to www.dropbox.com:443. HTTP request sent, awaiting response... 302 Found Location: https://uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com/cd/0/get/BPLx2MNsusc38Udla8CT9uo4AMVXZtKPfoHK5vJSvdbmPZTpSMeQOdbTzD_yQ7_zNOHjNuTsmnBEaCM2iVe0qwahbM0ZHpA4c78A85aAPTY-Df0rGcS48vw3DLmXO7gVk0b5hL9lfCc43L7no1OZt2I9/file?dl=1# [following] --2021-05-25 16:11:36-- https://uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com/cd/0/get/BPLx2MNsusc38Udla8CT9uo4AMVXZtKPfoHK5vJSvdbmPZTpSMeQOdbTzD_yQ7_zNOHjNuTsmnBEaCM2iVe0qwahbM0ZHpA4c78A85aAPTY-Df0rGcS48vw3DLmXO7gVk0b5hL9lfCc43L7no1OZt2I9/file?dl=1 Resolving uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com (uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f Connecting to uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com (uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com)|162.125.1.15|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20787027 (20M) [application/binary] Saving to: ‘Lung.tar.gz’ Lung.tar.gz 100%[===================&gt;] 19.82M 87.4MB/s in 0.2s 2021-05-25 16:11:37 (87.4 MB/s) - ‘Lung.tar.gz’ saved [20787027/20787027] Lung/ Lung/Lung_scanvi_model/ Lung/Lung_scanvi_model/var_names.csv Lung/Lung_scanvi_model/model_params.pt Lung/Lung_scanvi_model/attr.pkl Lung/Lung_scvi_model/ Lung/Lung_scvi_model/var_names.csv Lung/Lung_scvi_model/model_params.pt Lung/Lung_scvi_model/attr.pkl --2021-05-25 16:11:42-- https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1 Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112 Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: /s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb [following] --2021-05-25 16:11:43-- https://www.dropbox.com/s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb Reusing existing connection to www.dropbox.com:443. HTTP request sent, awaiting response... 302 Found Location: https://uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com/cd/0/get/BPI5oLsl-Ax20MWihfajGmmm5N3_9xi0x7lrQbXg-Xb2l9vUIR3HEoZlpiNUvqutYKJw5iBYljkhme6L-AArpmQhvA2742X2FCmjk8sV4XBK14GPS79kz3iuLnHhnmpux4PaexnWuHXsj759Kq7Mn_zB/file?dl=1# [following] --2021-05-25 16:11:43-- https://uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com/cd/0/get/BPI5oLsl-Ax20MWihfajGmmm5N3_9xi0x7lrQbXg-Xb2l9vUIR3HEoZlpiNUvqutYKJw5iBYljkhme6L-AArpmQhvA2742X2FCmjk8sV4XBK14GPS79kz3iuLnHhnmpux4PaexnWuHXsj759Kq7Mn_zB/file?dl=1 Resolving uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com (uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f Connecting to uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com (uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com)|162.125.1.15|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 87624137 (84M) [application/binary] Saving to: ‘cl.ontology.nlp.emb’ cl.ontology.nlp.emb 100%[===================&gt;] 83.56M 87.0MB/s in 1.0s 2021-05-25 16:11:45 (87.0 MB/s) - ‘cl.ontology.nlp.emb’ saved [87624137/87624137] . Setup the reference dataset . ref_adata_path = &#39;TS_{}.h5ad&#39;.format(tissue) ref_adata = anndata.read(ref_adata_path) . # This way we only train on expert annotated data ref_adata = ref_adata[ref_adata.obs[&quot;Manually Annotated&quot;] == &quot;True&quot;].copy() # We wish to correct for batch effects from donor and method # So we make a new batch key that will be passed to the methods ref_adata.obs[&#39;donor_method&#39;] = ref_adata.obs[&#39;Donor&#39;].astype(str) + ref_adata.obs[&#39;Method&#39;].astype(str) # The annotation pipeline expects raw counts in the the X field ref_adata.X = ref_adata.layers[&#39;raw_counts&#39;] # Following parameters are specific to Tabula Sapiens dataset ref_labels_key=&#39;Annotation&#39; ref_batch_key = &#39;donor_method&#39; . Check if we can use pretrained models . from annotation import get_pretrained_model_genes, check_genes_is_subset pretrained_scanvi_path = os.path.join(tissue, tissue + &quot;_scanvi_model&quot;) pretrained_scvi_path = os.path.join(tissue, tissue + &quot;_scvi_model&quot;) training_mode=&#39;online&#39; is_subset = False if training_mode == &#39;online&#39;: pretrained_genes = get_pretrained_model_genes(pretrained_scvi_path) query_genes = query_adata.var_names.to_numpy().astype(&quot;str&quot;) is_subset = check_genes_is_subset(pretrained_genes, query_genes) if is_subset and training_mode==&#39;online&#39;: ref_adata = ref_adata[:, pretrained_genes] else: training_mode = &#39;offline&#39; . Not all reference genes are in query dataset. Retraining models. . from annotation import process_query adata = process_query(query_adata, ref_adata, tissue=tissue, save_folder=save_folder, query_batch_key=query_batch_key, query_labels_key=query_labels_key, unknown_celltype_label=unknown_celltype_label, pretrained_scvi_path=pretrained_scvi_path, ref_labels_key=ref_labels_key, ref_batch_key=ref_batch_key, training_mode=training_mode, ref_adata_path=ref_adata_path) . Sampling 100 per label . /content/annotation.py:387: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy ref_adata.obs[&#34;_ref_subsample&#34;][ref_subsample_idx] = True /usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy iloc._setitem_with_indexer(indexer, value) . INFO Using batches from adata.obs[&#34;_batch_annotation&#34;] INFO Using labels from adata.obs[&#34;_labels_annotation&#34;] INFO Using data from adata.layers[&#34;scvi_counts&#34;] INFO Computing library size prior per batch INFO Successfully registered anndata object containing 104505 cells, 4000 vars, 6 batches, 36 labels, and 0 proteins. Also registered 0 extra categorical covariates and 0 extra continuous covariates. INFO Please do not further modify adata until model is trained. . ... storing &#39;method&#39; as categorical ... storing &#39;donor&#39; as categorical ... storing &#39;cell_ontology_type&#39; as categorical ... storing &#39;donor_method&#39; as categorical ... storing &#39;cell_ontology_id&#39; as categorical ... storing &#39;_batch_annotation&#39; as categorical ... storing &#39;_dataset&#39; as categorical ... storing &#39;final_annotation_cell_ontology_id&#39; as categorical ... storing &#39;_labels_annotation&#39; as categorical ... storing &#39;Annotation&#39; as categorical ... storing &#39;Manually Annotated&#39; as categorical ... storing &#39;Donor&#39; as categorical ... storing &#39;Method&#39; as categorical ... storing &#39;Organ&#39; as categorical ... storing &#39;Compartment&#39; as categorical ... storing &#39;Anatomical Information&#39; as categorical ... storing &#39;_batch_annotation&#39; as categorical ... storing &#39;_dataset&#39; as categorical ... storing &#39;final_annotation_cell_ontology_id&#39; as categorical ... storing &#39;_labels_annotation&#39; as categorical . adata . AnnData object with n_obs × n_vars = 104505 × 4000 obs: &#39;donor_method&#39;, &#39;_labels_annotation&#39;, &#39;_batch_annotation&#39;, &#39;_dataset&#39;, &#39;_ref_subsample&#39;, &#39;_scvi_batch&#39;, &#39;_scvi_labels&#39;, &#39;_scvi_local_l_mean&#39;, &#39;_scvi_local_l_var&#39; var: &#39;mean&#39;, &#39;std&#39;, &#39;highly_variable&#39;, &#39;highly_variable_rank&#39;, &#39;means&#39;, &#39;variances&#39;, &#39;variances_norm&#39; uns: &#39;_training_mode&#39;, &#39;log1p&#39;, &#39;hvg&#39;, &#39;pca&#39;, &#39;_scvi&#39; obsm: &#39;X_pca&#39; varm: &#39;PCs&#39; layers: &#39;scvi_counts&#39; . Step 5: Run Automated Cell Annotation Methods . No user action required. Takes about ~1 hour for a dataset for 100k cells. . Your results will be saved to the folder you provided as save_folder. . There will be the following files: . annotated_query.h5ad containing annotated query cells. The consensus annotations will be in consensus_prediction. There will also be a consensus_percentage field which is the percentage of methods that had the same prediction. | annotated_query_plus_ref.h5ad containing your query and the reference cells with predicted annotations. | confusion_matrices.pdf which contains the confusion matrices between the consensus_predictions and each individual method. | csv files containing the metrics for each confusion matrix. | . from annotation import annotate_data annotate_data(adata, methods, save_folder, pretrained_scvi_path=pretrained_scvi_path, pretrained_scanvi_path=pretrained_scanvi_path) . Integrating data with bbknn. Classifying with knn on bbknn distances. . /usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py:168: EfficiencyWarning: Precomputed sparse input was not sorted by data. EfficiencyWarning) /content/annotation.py:706: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred . Saved knn on bbknn results to adata.obs[&#34;knn_on_bbknn_pred&#34;] . ... storing &#39;knn_on_bbknn_pred&#39; as categorical ... storing &#39;knn_on_bbknn_pred&#39; as categorical . Running scVI. . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Training scvi offline. Epoch 77/77: 100%|██████████| 77/77 [04:00&lt;00:00, 3.13s/it, loss=778, v_num=1] Classifying with knn on scVI latent space. Training knn on scvi latent space. Using latent space in adata.obsm[&#34;X_scvi_offline&#34;] . /content/annotation.py:910: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred ... storing &#39;knn_on_scvi_offline_pred&#39; as categorical ... storing &#39;knn_on_scvi_offline_pred&#39; as categorical . Running scANVI. INFO Training for 77 epochs. . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Epoch 77/77: 100%|██████████| 77/77 [09:18&lt;00:00, 7.25s/it, loss=934, v_num=1] . ... storing &#39;scanvi_offline_pred&#39; as categorical ... storing &#39;scanvi_offline_pred&#39; as categorical . Classifying with SVM. . /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. &#34;the number of iterations.&#34;, ConvergenceWarning) /content/annotation.py:819: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_idx] = svm_pred ... storing &#39;svm_pred&#39; as categorical ... storing &#39;svm_pred&#39; as categorical . Classifying with random forest. Training random forest classifier with 2837 cells . /content/annotation.py:730: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_idx] = rf_pred ... storing &#39;rf_pred&#39; as categorical ... storing &#39;rf_pred&#39; as categorical . Running OnClass. init OnClass 29434 4000 35 2353 Training cost after epoch 1: loss:18.195199 acc: 0.848 auc: 0.971 auprc: 0.747 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 2: loss:6.472742 acc: 0.861 auc: 0.986 auprc: 0.784 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 3: loss:7.418795 acc: 0.891 auc: 0.990 auprc: 0.848 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 4: loss:6.403556 acc: 0.913 auc: 0.992 auprc: 0.876 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 5: loss:6.138159 acc: 0.906 auc: 0.993 auprc: 0.891 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 6: loss:3.145052 acc: 0.911 auc: 0.995 auprc: 0.905 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 7: loss:2.841035 acc: 0.937 auc: 0.996 auprc: 0.934 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 8: loss:3.699444 acc: 0.923 auc: 0.996 auprc: 0.941 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 9: loss:3.115471 acc: 0.922 auc: 0.994 auprc: 0.916 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 10: loss:2.733034 acc: 0.925 auc: 0.996 auprc: 0.927 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 11: loss:3.285794 acc: 0.929 auc: 0.996 auprc: 0.932 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 12: loss:2.393076 acc: 0.940 auc: 0.996 auprc: 0.920 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 13: loss:3.487159 acc: 0.945 auc: 0.997 auprc: 0.937 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 14: loss:3.418227 acc: 0.940 auc: 0.997 auprc: 0.934 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 15: loss:1.947167 acc: 0.949 auc: 0.998 auprc: 0.943 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 16: loss:1.995989 acc: 0.927 auc: 0.996 auprc: 0.947 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 17: loss:3.059286 acc: 0.940 auc: 0.996 auprc: 0.953 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 18: loss:1.990470 acc: 0.950 auc: 0.997 auprc: 0.960 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 19: loss:1.754694 acc: 0.952 auc: 0.998 auprc: 0.962 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 20: loss:1.563520 acc: 0.955 auc: 0.998 auprc: 0.970 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) Trying to set attribute `.obs` of view, copying. /content/annotation.py:786: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test_adata.obs[save_key][i : i + shard_size] = pred_label_str /content/annotation.py:786: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test_adata.obs[save_key][i : i + shard_size] = pred_label_str /content/annotation.py:794: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_adata.obs_names] = test_adata.obs[save_key] /usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy iloc._setitem_with_indexer(indexer, value) ... storing &#39;onclass_pred&#39; as categorical ... storing &#39;onclass_pred&#39; as categorical . Running scanorama. Found 4000 genes among all datasets [[0. 0.41865767 0.74522293 0.25761952 0.27251995 0.6864704 ] [0. 0. 0.52866242 0.29192949 0.2668187 0.1584653 ] [0. 0. 0. 0.23248408 0.28620296 0.60350318] [0. 0. 0. 0. 0.6704675 0.19555744] [0. 0. 0. 0. 0. 0.42189282] [0. 0. 0. 0. 0. 0. ]] Processing datasets (0, 2) Processing datasets (0, 5) Processing datasets (3, 4) Processing datasets (2, 5) Processing datasets (1, 2) Processing datasets (4, 5) Processing datasets (0, 1) Processing datasets (1, 3) Processing datasets (2, 4) Processing datasets (0, 4) Processing datasets (1, 4) Processing datasets (0, 3) Processing datasets (2, 3) Processing datasets (3, 5) Processing datasets (1, 5) Computing umap on scanorama Classifying with knn on scanorama latent space. Running knn on scanorama . /content/annotation.py:938: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred ... storing &#39;knn_on_scanorama_pred&#39; as categorical ... storing &#39;knn_on_scanorama_pred&#39; as categorical ... storing &#39;consensus_prediction&#39; as categorical ... storing &#39;consensus_percentage&#39; as categorical ... storing &#39;consensus_prediction&#39; as categorical ... storing &#39;consensus_percentage&#39; as categorical . Step 6 Generate Statistics and Figures . No user action required. . import pandas as pd import matplotlib.pyplot as plt results_file = os.path.join(save_folder,&#39;annotated_query_plus_ref.h5ad&#39;) results = anndata.read(results_file) . from annotation import make_agreement_plots all_prediction_keys = [ &quot;knn_on_bbknn_pred&quot;, &quot;knn_on_scvi_online_pred&quot;, &quot;knn_on_scvi_offline_pred&quot;, &quot;scanvi_online_pred&quot;, &quot;scanvi_offline_pred&quot;, &quot;svm_pred&quot;, &quot;rf_pred&quot;, &quot;onclass_pred&quot;, &quot;knn_on_scanorama_pred&quot;, ] obs_keys = adata.obs.keys() pred_keys = [key for key in obs_keys if key in all_prediction_keys] make_agreement_plots(results, methods=pred_keys, save_folder=save_folder) is_query = results.obs._dataset == &quot;query&quot; methods = [x for x in results.obs.columns if x.endswith(&quot;_pred&quot;)] labels = results.obs.consensus_prediction.astype(str) labels[~is_query] = results[~is_query].obs._labels_annotation.astype(str) celltypes = np.unique(labels) latent_methods = results.obsm.keys() . Making confusion matrix for knn_on_bbknn_pred Making confusion matrix for knn_on_scvi_offline_pred Making confusion matrix for scanvi_offline_pred Making confusion matrix for svm_pred Making confusion matrix for rf_pred Making confusion matrix for onclass_pred Making confusion matrix for knn_on_scanorama_pred . Distribution of consensus percentage . The more the algorithms agree with each other, the better the annotation has worked . agreement_counts = pd.DataFrame( np.unique(results[is_query].obs[&quot;consensus_percentage&quot;], return_counts=True) ).T agreement_counts.columns = [&quot;Percent Agreement&quot;, &quot;Count&quot;] agreement_counts.plot.bar( x=&quot;Percent Agreement&quot;, y=&quot;Count&quot;, legend=False, figsize=(4, 3) ) plt.ylabel(&quot;Frequency&quot;) plt.xlabel(&quot;Percent of Algorithms Agreeing with Majority Vote&quot;) figpath = os.path.join(save_folder, &quot;Concensus_Percentage_barplot.pdf&quot;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) . Per cell type agreement . Some cell types can be better predicted than others, and we can highlight the celltypes that are poorly predicted by looking at the per celltype agreement. The cell types are separated by the concensus predictions. . mean_agreement = [ np.mean(results[is_query &amp; (labels == x)].obs[&quot;consensus_percentage&quot;].astype(float)) for x in celltypes ] mean_agreement = pd.DataFrame([mean_agreement], index=[&quot;agreement&quot;]).T mean_agreement.index = celltypes mean_agreement = mean_agreement.sort_values(&quot;agreement&quot;, ascending=True) mean_agreement.plot.bar(y=&quot;agreement&quot;, figsize=(15, 2), legend=False) plt.ylabel(&quot;Mean Agreement&quot;) plt.xticks(rotation=290, ha=&quot;left&quot;) figpath = os.path.join(save_folder, &quot;percelltype_agreement_barplot.pdf&quot;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) . Cell type proportion plot . prop = pd.DataFrame(index=celltypes, columns=[&quot;ref&quot;, &quot;query&quot;]) for x in celltypes: prop.loc[x, &quot;query&quot;] = np.sum(labels[is_query] == x) prop.loc[x, &quot;ref&quot;] = np.sum(labels[~is_query] == x) . prop.loc[mean_agreement.index].plot(kind=&#39;bar&#39;, figsize=(len(celltypes)*0.5,4),logy=True) plt.legend(bbox_to_anchor=(1, 0.9)) plt.ylabel(&#39;log Celltype Abundance&#39;) plt.tight_layout() figpath = os.path.join(save_folder, &#39;celltype_prop_barplot.pdf&#39;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) plt.show() plt.close() .",
            "url": "https://vikkki.github.io/vikkki_blog/python/jupyter/singlecell/annotation/2022/02/09/Automated_Cell_Annotation.html",
            "relUrl": "/python/jupyter/singlecell/annotation/2022/02/09/Automated_Cell_Annotation.html",
            "date": " • Feb 9, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Computational annotation of doublets with scds on Seurat object",
            "content": "Sometimes when we see an &quot;unexpectied&quot; cluster or group, one of the possible causes could be doublets. Treating doublets as single cells in downstream analyses can bias a study’s conclusions. Here we can use scds, which implamented two new approaches to identify doublets(Co-expression based doublet scoring cxds and binary classification based doublet scoring bcds) to elaluate doublets scores. . For more guides, check scds&#39;s page. . set.seed(8887) . library(scds, verbose = FALSE) library(scater, verbose = FALSE) library(rsvd, verbose = FALSE) library(Rtsne, verbose = FALSE) library(cowplot, verbose = FALSE) library(scater, verbose = FALSE) library(patchwork, verbose = FALSE) library(Seurat, verbose = FALSE) library(SeuratData, verbose = FALSE) library(dplyr) . We first load the data (download available here), it&#39;s a reference scRNA-seq dataset of ~14,000 adult mouse cortical cell taxonomy from the Allen Institute, generated with the SMART-Seq2 protocol. . allen_reference &lt;- readRDS(&quot;~/Documents/blog_notes/allen_cortex.rds&quot;) . Convert to SingleCellExperimentobject brain.ref.sce &lt;- as.SingleCellExperiment(allen_reference) . dim(brain.ref.sce) . &lt;ol class=list-inline&gt;34617 | 14249 | &lt;/ol&gt; table(brain.ref.sce$subclass) . Astro CR Endo L2/3 IT L4 L5 IT L5 PT 368 7 94 982 1401 880 544 L6 CT L6 IT L6b Lamp5 Macrophage Meis2 NP 960 1872 358 1122 51 45 362 Oligo Peri Pvalb Serpinf1 SMC Sncg Sst 91 32 1337 27 55 125 1741 Vip VLMC 1728 67 . Visualize: . logcounts(brain.ref.sce) = log1p(counts(brain.ref.sce)) vrs = apply(logcounts(brain.ref.sce),1,var) pc = rpca(t(logcounts(brain.ref.sce)[order(vrs,decreasing=TRUE)[1:100],])) ts = Rtsne(pc$x[,1:10],verb=FALSE) . options(repr.plot.width=12, repr.plot.height=8) . reducedDim(brain.ref.sce,&quot;tsne&quot;) = ts$Y; rm(ts,vrs,pc) . plotReducedDim(brain.ref.sce,&quot;tsne&quot;,col=&quot;subclass&quot;) . Annotate doublet using co-expression based doublet scoring . brain.ref.sce = cxds(brain.ref.sce,retRes = TRUE) brain.ref.sce = bcds(brain.ref.sce,retRes = TRUE,verb=TRUE) . -&gt; selecting genes -&gt; simulating doublets -&gt; training classifier . [01:32:23] WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;binary:logistic&#39; was changed from &#39;error&#39; to &#39;logloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior. . -&gt; done. . brain.ref.sce = cxds_bcds_hybrid(brain.ref.sce) plotReducedDim(brain.ref.sce,&quot;tsne&quot;,col=&quot;hybrid_score&quot;) . options(repr.plot.width=20, repr.plot.height=8) boxplot(brain.ref.sce$hybrid_score ~ brain.ref.sce$subclass, main=&quot;hybrid&quot;) . Export scores and load it back into thge original Seurat object: . metadata = as.data.frame(colData(brain.ref.sce)) hyb_doublet_score = select(metadata, hybrid_score) . allen_reference &lt;- AddMetaData(allen_reference, metadata = hyb_doublet_score, col.name = &#39;hybrid.score&#39;) . allen_reference_3000 &lt;- allen_reference[,sample(colnames(allen_reference), size =3000, replace=F)] . allen_reference_3000 &lt;- SCTransform(allen_reference_3000, ncells = 3000, verbose = FALSE) %&gt;% RunPCA(verbose = FALSE) %&gt;% RunUMAP(dims = 1:30) . DimPlot(allen_reference_3000, group.by = &quot;subclass&quot;, label = TRUE) . options(repr.plot.width=10, repr.plot.height=8) FeaturePlot(allen_reference_3000, features = &quot;hybrid.score&quot;, label = TRUE, pt.size=4) . 3 min is a lie :cake: . Session information . sessionInfo() . R version 4.1.2 (2021-11-01) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux 11 (bullseye) Matrix products: default BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0 LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0 locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats4 stats graphics grDevices utils datasets methods [8] base other attached packages: [1] dplyr_1.0.8 stxBrain.SeuratData_0.1.1 [3] SeuratData_0.2.1 SeuratObject_4.0.4 [5] Seurat_4.1.0 patchwork_1.1.1 [7] cowplot_1.1.1 Rtsne_0.15 [9] rsvd_1.0.5 scater_1.22.0 [11] ggplot2_3.3.5 scuttle_1.4.0 [13] SingleCellExperiment_1.16.0 SummarizedExperiment_1.24.0 [15] Biobase_2.54.0 GenomicRanges_1.46.1 [17] GenomeInfoDb_1.30.1 IRanges_2.28.0 [19] S4Vectors_0.32.3 BiocGenerics_0.40.0 [21] MatrixGenerics_1.6.0 matrixStats_0.61.0 [23] scds_1.9.1 loaded via a namespace (and not attached): [1] uuid_1.0-3 plyr_1.8.6 [3] igraph_1.2.11 repr_1.1.4 [5] lazyeval_0.2.2 splines_4.1.2 [7] BiocParallel_1.28.3 listenv_0.8.0 [9] scattermore_0.7 digest_0.6.29 [11] htmltools_0.5.2 viridis_0.6.2 [13] fansi_1.0.2 magrittr_2.0.2 [15] ScaledMatrix_1.2.0 tensor_1.5 [17] cluster_2.1.2 ROCR_1.0-11 [19] globals_0.14.0 spatstat.sparse_2.1-0 [21] colorspace_2.0-2 rappdirs_0.3.3 [23] ggrepel_0.9.1 crayon_1.4.2 [25] RCurl_1.98-1.6 jsonlite_1.7.3 [27] spatstat.data_2.1-2 survival_3.2-13 [29] zoo_1.8-9 glue_1.6.1 [31] polyclip_1.10-0 gtable_0.3.0 [33] zlibbioc_1.40.0 XVector_0.34.0 [35] leiden_0.3.9 DelayedArray_0.20.0 [37] BiocSingular_1.10.0 future.apply_1.8.1 [39] abind_1.4-5 scales_1.1.1 [41] DBI_1.1.2 miniUI_0.1.1.1 [43] Rcpp_1.0.8 viridisLite_0.4.0 [45] xtable_1.8-4 reticulate_1.24 [47] spatstat.core_2.3-2 htmlwidgets_1.5.4 [49] httr_1.4.2 RColorBrewer_1.1-2 [51] ellipsis_0.3.2 ica_1.0-2 [53] farver_2.1.0 pkgconfig_2.0.3 [55] uwot_0.1.11 deldir_1.0-6 [57] utf8_1.2.2 labeling_0.4.2 [59] tidyselect_1.1.1 rlang_1.0.1 [61] reshape2_1.4.4 later_1.3.0 [63] munsell_0.5.0 tools_4.1.2 [65] xgboost_1.5.0.2 cli_3.1.1 [67] generics_0.1.2 ggridges_0.5.3 [69] evaluate_0.14 stringr_1.4.0 [71] fastmap_1.1.0 goftest_1.2-3 [73] fitdistrplus_1.1-6 purrr_0.3.4 [75] RANN_2.6.1 nlme_3.1-155 [77] pbapply_1.5-0 future_1.23.0 [79] sparseMatrixStats_1.6.0 mime_0.12 [81] compiler_4.1.2 beeswarm_0.4.0 [83] plotly_4.10.0 png_0.1-7 [85] spatstat.utils_2.3-0 tibble_3.1.6 [87] stringi_1.7.6 RSpectra_0.16-0 [89] lattice_0.20-45 IRdisplay_1.1 [91] Matrix_1.4-0 vctrs_0.3.8 [93] pillar_1.7.0 lifecycle_1.0.1 [95] spatstat.geom_2.3-1 lmtest_0.9-39 [97] RcppAnnoy_0.0.19 BiocNeighbors_1.12.0 [99] data.table_1.14.2 bitops_1.0-7 [101] irlba_2.3.5 httpuv_1.6.5 [103] R6_2.5.1 promises_1.2.0.1 [105] KernSmooth_2.23-20 gridExtra_2.3 [107] vipor_0.4.5 parallelly_1.30.0 [109] codetools_0.2-18 MASS_7.3-55 [111] assertthat_0.2.1 withr_2.4.3 [113] sctransform_0.3.3 GenomeInfoDbData_1.2.7 [115] mgcv_1.8-38 parallel_4.1.2 [117] rpart_4.1.16 grid_4.1.2 [119] beachmat_2.10.0 IRkernel_1.3.0.9000 [121] tidyr_1.2.0 DelayedMatrixStats_1.16.0 [123] pbdZMQ_0.3-7 pROC_1.18.0 [125] shiny_1.7.1 base64enc_0.1-3 [127] ggbeeswarm_0.6.0 .",
            "url": "https://vikkki.github.io/vikkki_blog/r/jupyter/singlecell/seurat/scds/2022/02/08/Computational-annotation-of-doublets.html",
            "relUrl": "/r/jupyter/singlecell/seurat/scds/2022/02/08/Computational-annotation-of-doublets.html",
            "date": " • Feb 8, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Run cellranger count on multiple samples interactively with python",
            "content": "This notebook includes several simple functions to help generate and run cellranger count commends, and gather the summary pages and output folder from seperate sample run directories. . import os,shutil,re import subprocess . %config ZMQInteractiveShell.ast_node_interactivity = &quot;all&quot; . Check current work path: . cfolder = os.getcwd() cfolder . &#39;/mnt/data_processing/10xRNA_working/20220202_Polverino_sc5prime_GEX_miseq&#39; . def get_count_result_folder_list(cfolder): folders_list = next(os.walk(cfolder, followlinks = False))[1] result_folder_list = [] for folder in folders_list: if os.path.isfile(cfolder + &quot;/&quot; + folder + &quot;/outs/web_summary.html&quot;): result_folder_list.append(folder) return result_folder_list def get_sample_names(fastq_path): sample_names = [] for fastq in os.listdir(fastq_path): sample_names.append(re.split(&#39;[_]&#39;, fastq)[0]) sample_names = list(set(sample_names)) return sample_names ### cellranger count commend construction: def get_cellranger_count_cmd(sample,fastq_path): a = &#39;&#39; cmd = a.join([cellranger, &quot; count --transcriptome &quot;, transcriptome, &quot; --fastqs &quot;, fastq_path, &quot; --localcores=24 --localmem=100 --no-bam&quot;, &quot; --id &quot;, sample, &quot; --sample &quot;, sample]) return cmd # &quot; --expect-cells=5000&quot; def run_cellranger_for_sample_list(sample_names, fastq_path): for sample in sample_names: cmd = get_cellranger_count_cmd(sample,fastq_path) print(&quot;- n Runing count n- n&quot; + sample + &quot;- n&quot;) print(cmd) print(&quot;&quot;) res1 = subprocess.Popen(cmd, shell = True, stdout = subprocess.PIPE, stderr = subprocess.PIPE) print(str(res1.communicate()[0],&quot;utf-8&quot;)) def gather_summaries(cfolder): if not os.path.exists(cfolder + &quot;/cellranger_web_summaries&quot;): print(&quot;Creating folder...&quot;) os.makedirs(cfolder + &quot;/cellranger_web_summaries&quot;) print(&quot;Folder created, Ready.&quot;) else: print(&quot;Summary folder exists, Ready.&quot;) flist = get_count_result_folder_list(cfolder) for folder in flist: shutil.copyfile(cfolder + &quot;/&quot; + folder + &quot;/outs/web_summary.html&quot;, cfolder + &quot;/cellranger_web_summaries/&quot; + folder + &quot;_web_summary.html&quot;) print(folder + &quot; Coppied.&quot;) print(&quot;Finished.&quot;) . Add the path to formated fastqs: . fastq_path = &quot;./fastq_checking/&quot; . Setup ref genome and software version: . transcriptome = &quot;/data_1T/ref/hm/refdata-gex-GRCh38-2020-A&quot; # transcriptome = &quot;/data_1T/ref/mm/refdata-cellranger-mm10-3.0.0&quot; # transcriptome = &quot;/data_1T/ref/rn/Rnor_6.0&quot; # cellranger = &#39;/home/xiaofan/Biotools/cellranger-6.0.2/cellranger&#39; # cellranger = &#39;/home/xiaofan/Biotools/cellranger-6.1.1/cellranger&#39; cellranger = &#39;/home/xiaofan/Biotools/cellranger-6.1.2/cellranger&#39; . Check sample names: . sample_names = get_sample_names(fastq_path) sample_names . [&#39;multiqc&#39;, &#39;69-20200902-cryo-lung-ssp-GEX&#39;] . Start cellrange count: . run_cellranger_for_sample_list(sample_names, fastq_path) . Collect and rename summary pages . gather_summaries(cfolder) . Creating folder... Folder created, Ready. 69-20200902-cryo-lung-ssp-GEX-manual Coppied. 90-20210121-cryo-lung-susp-GEX Coppied. 73-20200924-cryo-lung-susp-GEX Coppied. 70-20200910-cryo-lung-susp-GEX Coppied. 74-20201001-cryo-lung-susp-GEX Coppied. 69-20200902-cryo-lung-ssp-GEX Coppied. 78-20201112-cryo-lung-susp-GEX Coppied. UA94-RUL-cryo-lung-susp-20210311-GEX Coppied. 72-20200917-cryo-lung-ssp-GEX Coppied. UA96-20210325-lung-cryo-GEX Coppied. Finished. . def gather_count_output(cfolder): if not os.path.exists(cfolder + &quot;/cellranger_count_output&quot;): print(&quot;Creating folder...&quot;) os.makedirs(cfolder + &quot;/cellranger_count_output&quot;) print(&quot;Done.&quot;) else: print(&quot;Output folder exists, Ready.&quot;) flist = get_count_result_folder_list(cfolder) for folder in flist: shutil.copytree(cfolder + &quot;/&quot; + folder + &quot;/outs&quot;, cfolder + &quot;/cellranger_count_output/&quot; + folder + &quot;_out&quot;) print(folder + &quot; Coppied.&quot;) print(&quot;Finished.&quot;) . If needed, collect the entire count output folder(can take up to minutes if bam files included) . gather_count_output(cfolder) . Creating folder... Done. S3 Coppied. S2 Coppied. M5 Coppied. P3 Coppied. M3 Coppied. M6 Coppied. S1 Coppied. P1 Coppied. M4 Coppied. M1 Coppied. PA Coppied. P5 Coppied. P2 Coppied. M2 Coppied. Finished. .",
            "url": "https://vikkki.github.io/vikkki_blog/python/jupyter/singlecell/cellranger/2021/09/12/Cellranger-count-python.html",
            "relUrl": "/python/jupyter/singlecell/cellranger/2021/09/12/Cellranger-count-python.html",
            "date": " • Sep 12, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Graduate student at the USC, Transnational Bioinformatics project, and a gardener. . Github page here: https://github.com/vikkki . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://vikkki.github.io/vikkki_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://vikkki.github.io/vikkki_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}