{
  
    
        "post0": {
            "title": "Automated_Cell_Annotation",
            "content": "This notebook allows you to annotate your data with a number of annotation methods using the Tabula Sapiens dataset as the reference. . Initial setup: . Make sure GPU is enabled (Runtime -&gt; Change Runtime Type -&gt; Hardware Accelerator -&gt; GPU) | We also highly recommend getting Colab PRO for access to a high ram session. | Integration Methods Provided: . scVI | bbKNN | scanorama | . Annotation Methods: . KNN on integrated spaces | scANVI | onClass | SVM | RandomForest | . To use the notebook, simply connect to your Google Drive account, set the necessary arguments, select your methods, and run all the code blocks! . *User action is only required in Step 2 and Step 3. . Step 1: Setup Environment . No user input required here. . %%capture #@title Setup Colab #@markdown Here we install the necessary packages #@markdown This will take a few minutes (~5 min) import sys import os !pip install --quiet obonet !pip install --quiet --upgrade jsonschema !pip install --quiet bbknn !pip install --quiet git+https://github.com/wangshenguiuc/OnClass@21232f293a549a7ee0da8ebe3cbb22df3e885d4c !pip install --quiet git+https://github.com/yoseflab/scvi-tools@master#egg=scvi-tools[tutorials] !pip install --quiet imgkit !pip install --quiet gdown !pip install --quiet --upgrade scanorama # Download annoation code !wget -O annotation.py -q https://www.dropbox.com/s/id8sallwrunjc5c/annotation.py?dl=1 . import anndata import numpy as np import scanpy as sc import scvi . Step 2: Load your data (User Action Required) . Here we provide three options to load your data: . Connect to Google Drive (highly recommended) | Download your data from the cloud and save into this session or on Google drive. | Upload your data manually into this session (files are not persistent and will be deleted when session is closed) | As an example, we use a subsampled version of the Lung Cell Atlas [1] for our query data. . [1] Travaglini, K. et al. A molecular cell atlas of the human lung from single-cell RNA sequencing. Nature 587, 619–625(2020). . # This is the recomended method especially for large datasets from google.colab import drive drive.mount(&#39;/content/drive&#39;) query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . # Google Colab supports wget, curl, and gdown commands # It is recommended to download the data into Google Drive and read from there. # This way your data will be persistent. !wget &lt;YOUR URL&gt; query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . # Click the folder icon on the left navigation bar, and select the upload icon # Note: Manually uploaded data is automatically deleted when the colab session ends # This is not recommended if your dataset is very large query_adata = anndata.read(&#39;/path/to/your/anndata&#39;) . !wget -O LCA.h5ad https://www.dropbox.com/s/mrf8y7emfupo4he/LCA.h5ad?dl=1 query_adata = anndata.read(&#39;LCA.h5ad&#39;) . query_adata . AnnData object with n_obs × n_vars = 75071 × 23681 obs: &#39;method&#39;, &#39;donor&#39;, &#39;cell_ontology_type&#39;, &#39;donor_method&#39;, &#39;cell_ontology_id&#39; . Check that query_adata.X contains raw_counts . from annotation import _check_nonnegative_integers assert _check_nonnegative_integers(query_adata.X) == True, &#39;Make sure query_adata.X contains raw_counts&#39; . Step 3: Setting Up Annotation Parameters (User Action Required) . Here is where you set the parameters for the automated annotation. . Arguments: . tissue: Tabula Sapiens tissue to annotate your data with. Available tissues: [&quot;Bladder&quot;, &quot;Blood&quot;, &quot;Bone_Marrow&quot;, &quot;Kidney&quot;, &quot;Large_Intestine&quot;, &quot;Lung&quot;,&quot;Lymph_Node&quot;, &quot;Pancreas&quot;, &quot;Small_Intestine&quot;, &quot;Spleen&quot;, &quot;Thymus&quot;,&quot;Trachea&quot;, &quot;Vasculature&quot;] | save_location: location to save results to. By default will save to a folder named annotation_results. It is highly recommended you provide a Google Drive folder here. | query_batch_key: key in query_adata.obs for batch correction. Set to None for no batch correction. | methods: these are the methods to run. By default, will run all methods. | training_mode can be online or offline. If offline will train scVI and scANVI models from scratch. If online, will use pretrained models. | . Lesser used parameters . query_labels_key: scANVI has the option to use labeled cells in the query dataset during training. To use some prelabeled cells from the query dataset, set query_labels_key to the corresponding key in query_adata.obs | unknown_celltype_label: If query_labels_key is not None, will treat everything not labeled unknown_celltype_label as a labeled cell | . &quot;&quot;&quot; tissue options: [&quot;Bladder&quot;, &quot;Blood&quot;, &quot;Bone_Marrow&quot;, &quot;Kidney&quot;, &quot;Large_Intestine&quot;, &quot;Lung&quot;, &quot;Lymph_Node&quot;, &quot;Pancreas&quot;, &quot;Small_Intestine&quot;, &quot;Spleen&quot;, &quot;Thymus&quot;, &quot;Trachea&quot;, &quot;Vasculature&quot;] &quot;&quot;&quot; tissue = &#39;Lung&#39; save_folder = &#39;./&#39; query_batch_key = &#39;method&#39; methods = [&#39;bbknn&#39;,&#39;scvi&#39;, &#39;scanvi&#39;, &#39;svm&#39;, &#39;rf&#39;, &#39;onclass&#39;, &#39;scanorama&#39;] training_mode=&#39;online&#39; # Lesser used parameters query_labels_key=None unknown_celltype_label=&#39;unknown&#39; . Step 4: Downloading Reference Data and Pretrained Models . No more user input required! Just run all the following code blocks. . if tissue == &#39;Bladder&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388874&#39; pretrained_url=&#39;https://www.dropbox.com/s/rb89y577l6vs2mm/Bladder.tar.gz?dl=1&#39; elif tissue == &#39;Blood&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388853&#39; pretrained_url = &#39;https://www.dropbox.com/s/kyh9nv202n0db65/Blood.tar.gz?dl=1&#39; elif tissue == &#39;Bone_Marrow&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388841&#39; pretrained_url = &#39;https://www.dropbox.com/s/a3r4ddg7o7kua7z/Bone_Marrow.tar.gz?dl=1&#39; elif tissue == &#39;Kidney&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388838&#39; pretrained_url = &#39;https://www.dropbox.com/s/k41r1a346z0tuip/Kidney.tar.gz?dl=1&#39; elif tissue == &#39;Large_Intestine&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388835&#39; pretrained_url = &#39;https://www.dropbox.com/s/jwvpk727hd54byd/Large_Intestine.tar.gz?dl=1&#39; elif tissue == &#39;Lung&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388832&#39; pretrained_url = &#39;https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1&#39; elif tissue == &#39;Lymph_Node&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388715&#39; pretrained_url = &#39;https://www.dropbox.com/s/mbejy9tcbx9e1yv/Lymph_Node.tar.gz?dl=1&#39; elif tissue == &#39;Pancreas&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388613&#39; pretrained_url = &#39;https://www.dropbox.com/s/r3klvr22m6kq143/Pancreas.tar.gz?dl=1&#39; elif tissue == &#39;Small_Intestine&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388559&#39; pretrained_url = &#39;https://www.dropbox.com/s/7eiv2mke70jinzc/Small_Intestine.tar.gz?dl=1&#39; elif tissue == &#39;Spleen&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388544&#39; pretrained_url = &#39;https://www.dropbox.com/s/6j3iwahsjnb8rb3/Spleen.tar.gz?dl=1&#39; elif tissue == &#39;Thymus&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388505&#39; pretrained_url=&#39;https://www.dropbox.com/s/9k0mneu2wvpiudz/Thymus.tar.gz?dl=1&#39; elif tissue == &#39;Trachea&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388460&#39; pretrained_url = &#39;https://www.dropbox.com/s/57tthfgkl8jtxk6/Trachea.tar.gz?dl=1&#39; elif tissue == &#39;Vasculature&#39;: refdata_url = &#39;https://ndownloader.figshare.com/files/27388451&#39; pretrained_url=&#39;https://www.dropbox.com/s/1wt3r871kxjas5o/Vasculature.tar.gz?dl=1&#39; # Download reference dataset output_fn = &#39;TS_{}.h5ad&#39;.format(tissue) !wget -O $output_fn $refdata_url # Download pretrained scVI and scANVI models. output_fn = &#39;{}.tar.gz&#39;.format(tissue) !wget -O $output_fn $pretrained_url !tar -xvzf $output_fn # Download onclass files !wget -O cl.obo -q https://www.dropbox.com/s/hodp0etapzrd8ak/cl.obo?dl=1 !wget -O cl.ontology -q https://www.dropbox.com/s/nes0zprzfbwbgj5/cl.ontology?dl=1 !wget -O cl.ontology.nlp.emb https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1 . --2021-05-25 16:09:11-- https://ndownloader.figshare.com/files/27388832 Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 18.202.93.19, 3.248.64.20, 34.249.85.89, ... Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|18.202.93.19|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2673660872 (2.5G) [application/octet-stream] Saving to: ‘TS_Lung.h5ad’ TS_Lung.h5ad 100%[===================&gt;] 2.49G 20.3MB/s in 2m 23s 2021-05-25 16:11:35 (17.8 MB/s) - ‘TS_Lung.h5ad’ saved [2673660872/2673660872] --2021-05-25 16:11:35-- https://www.dropbox.com/s/e4al4ia9hm9qtcg/Lung.tar.gz?dl=1 Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112 Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: /s/dl/e4al4ia9hm9qtcg/Lung.tar.gz [following] --2021-05-25 16:11:36-- https://www.dropbox.com/s/dl/e4al4ia9hm9qtcg/Lung.tar.gz Reusing existing connection to www.dropbox.com:443. HTTP request sent, awaiting response... 302 Found Location: https://uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com/cd/0/get/BPLx2MNsusc38Udla8CT9uo4AMVXZtKPfoHK5vJSvdbmPZTpSMeQOdbTzD_yQ7_zNOHjNuTsmnBEaCM2iVe0qwahbM0ZHpA4c78A85aAPTY-Df0rGcS48vw3DLmXO7gVk0b5hL9lfCc43L7no1OZt2I9/file?dl=1# [following] --2021-05-25 16:11:36-- https://uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com/cd/0/get/BPLx2MNsusc38Udla8CT9uo4AMVXZtKPfoHK5vJSvdbmPZTpSMeQOdbTzD_yQ7_zNOHjNuTsmnBEaCM2iVe0qwahbM0ZHpA4c78A85aAPTY-Df0rGcS48vw3DLmXO7gVk0b5hL9lfCc43L7no1OZt2I9/file?dl=1 Resolving uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com (uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f Connecting to uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com (uc00cd061d464e593e097d52d472.dl.dropboxusercontent.com)|162.125.1.15|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20787027 (20M) [application/binary] Saving to: ‘Lung.tar.gz’ Lung.tar.gz 100%[===================&gt;] 19.82M 87.4MB/s in 0.2s 2021-05-25 16:11:37 (87.4 MB/s) - ‘Lung.tar.gz’ saved [20787027/20787027] Lung/ Lung/Lung_scanvi_model/ Lung/Lung_scanvi_model/var_names.csv Lung/Lung_scanvi_model/model_params.pt Lung/Lung_scanvi_model/attr.pkl Lung/Lung_scvi_model/ Lung/Lung_scvi_model/var_names.csv Lung/Lung_scvi_model/model_params.pt Lung/Lung_scvi_model/attr.pkl --2021-05-25 16:11:42-- https://www.dropbox.com/s/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb?dl=1 Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112 Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: /s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb [following] --2021-05-25 16:11:43-- https://www.dropbox.com/s/dl/y9x9yt2pi7s0d1n/cl.ontology.nlp.emb Reusing existing connection to www.dropbox.com:443. HTTP request sent, awaiting response... 302 Found Location: https://uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com/cd/0/get/BPI5oLsl-Ax20MWihfajGmmm5N3_9xi0x7lrQbXg-Xb2l9vUIR3HEoZlpiNUvqutYKJw5iBYljkhme6L-AArpmQhvA2742X2FCmjk8sV4XBK14GPS79kz3iuLnHhnmpux4PaexnWuHXsj759Kq7Mn_zB/file?dl=1# [following] --2021-05-25 16:11:43-- https://uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com/cd/0/get/BPI5oLsl-Ax20MWihfajGmmm5N3_9xi0x7lrQbXg-Xb2l9vUIR3HEoZlpiNUvqutYKJw5iBYljkhme6L-AArpmQhvA2742X2FCmjk8sV4XBK14GPS79kz3iuLnHhnmpux4PaexnWuHXsj759Kq7Mn_zB/file?dl=1 Resolving uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com (uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f Connecting to uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com (uc0981cbd9a1ca5a7aa85ed067a3.dl.dropboxusercontent.com)|162.125.1.15|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 87624137 (84M) [application/binary] Saving to: ‘cl.ontology.nlp.emb’ cl.ontology.nlp.emb 100%[===================&gt;] 83.56M 87.0MB/s in 1.0s 2021-05-25 16:11:45 (87.0 MB/s) - ‘cl.ontology.nlp.emb’ saved [87624137/87624137] . Setup the reference dataset . ref_adata_path = &#39;TS_{}.h5ad&#39;.format(tissue) ref_adata = anndata.read(ref_adata_path) . # This way we only train on expert annotated data ref_adata = ref_adata[ref_adata.obs[&quot;Manually Annotated&quot;] == &quot;True&quot;].copy() # We wish to correct for batch effects from donor and method # So we make a new batch key that will be passed to the methods ref_adata.obs[&#39;donor_method&#39;] = ref_adata.obs[&#39;Donor&#39;].astype(str) + ref_adata.obs[&#39;Method&#39;].astype(str) # The annotation pipeline expects raw counts in the the X field ref_adata.X = ref_adata.layers[&#39;raw_counts&#39;] # Following parameters are specific to Tabula Sapiens dataset ref_labels_key=&#39;Annotation&#39; ref_batch_key = &#39;donor_method&#39; . Check if we can use pretrained models . from annotation import get_pretrained_model_genes, check_genes_is_subset pretrained_scanvi_path = os.path.join(tissue, tissue + &quot;_scanvi_model&quot;) pretrained_scvi_path = os.path.join(tissue, tissue + &quot;_scvi_model&quot;) training_mode=&#39;online&#39; is_subset = False if training_mode == &#39;online&#39;: pretrained_genes = get_pretrained_model_genes(pretrained_scvi_path) query_genes = query_adata.var_names.to_numpy().astype(&quot;str&quot;) is_subset = check_genes_is_subset(pretrained_genes, query_genes) if is_subset and training_mode==&#39;online&#39;: ref_adata = ref_adata[:, pretrained_genes] else: training_mode = &#39;offline&#39; . Not all reference genes are in query dataset. Retraining models. . from annotation import process_query adata = process_query(query_adata, ref_adata, tissue=tissue, save_folder=save_folder, query_batch_key=query_batch_key, query_labels_key=query_labels_key, unknown_celltype_label=unknown_celltype_label, pretrained_scvi_path=pretrained_scvi_path, ref_labels_key=ref_labels_key, ref_batch_key=ref_batch_key, training_mode=training_mode, ref_adata_path=ref_adata_path) . Sampling 100 per label . /content/annotation.py:387: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy ref_adata.obs[&#34;_ref_subsample&#34;][ref_subsample_idx] = True /usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy iloc._setitem_with_indexer(indexer, value) . INFO Using batches from adata.obs[&#34;_batch_annotation&#34;] INFO Using labels from adata.obs[&#34;_labels_annotation&#34;] INFO Using data from adata.layers[&#34;scvi_counts&#34;] INFO Computing library size prior per batch INFO Successfully registered anndata object containing 104505 cells, 4000 vars, 6 batches, 36 labels, and 0 proteins. Also registered 0 extra categorical covariates and 0 extra continuous covariates. INFO Please do not further modify adata until model is trained. . ... storing &#39;method&#39; as categorical ... storing &#39;donor&#39; as categorical ... storing &#39;cell_ontology_type&#39; as categorical ... storing &#39;donor_method&#39; as categorical ... storing &#39;cell_ontology_id&#39; as categorical ... storing &#39;_batch_annotation&#39; as categorical ... storing &#39;_dataset&#39; as categorical ... storing &#39;final_annotation_cell_ontology_id&#39; as categorical ... storing &#39;_labels_annotation&#39; as categorical ... storing &#39;Annotation&#39; as categorical ... storing &#39;Manually Annotated&#39; as categorical ... storing &#39;Donor&#39; as categorical ... storing &#39;Method&#39; as categorical ... storing &#39;Organ&#39; as categorical ... storing &#39;Compartment&#39; as categorical ... storing &#39;Anatomical Information&#39; as categorical ... storing &#39;_batch_annotation&#39; as categorical ... storing &#39;_dataset&#39; as categorical ... storing &#39;final_annotation_cell_ontology_id&#39; as categorical ... storing &#39;_labels_annotation&#39; as categorical . adata . AnnData object with n_obs × n_vars = 104505 × 4000 obs: &#39;donor_method&#39;, &#39;_labels_annotation&#39;, &#39;_batch_annotation&#39;, &#39;_dataset&#39;, &#39;_ref_subsample&#39;, &#39;_scvi_batch&#39;, &#39;_scvi_labels&#39;, &#39;_scvi_local_l_mean&#39;, &#39;_scvi_local_l_var&#39; var: &#39;mean&#39;, &#39;std&#39;, &#39;highly_variable&#39;, &#39;highly_variable_rank&#39;, &#39;means&#39;, &#39;variances&#39;, &#39;variances_norm&#39; uns: &#39;_training_mode&#39;, &#39;log1p&#39;, &#39;hvg&#39;, &#39;pca&#39;, &#39;_scvi&#39; obsm: &#39;X_pca&#39; varm: &#39;PCs&#39; layers: &#39;scvi_counts&#39; . Step 5: Run Automated Cell Annotation Methods . No user action required. Takes about ~1 hour for a dataset for 100k cells. . Your results will be saved to the folder you provided as save_folder. . There will be the following files: . annotated_query.h5ad containing annotated query cells. The consensus annotations will be in consensus_prediction. There will also be a consensus_percentage field which is the percentage of methods that had the same prediction. | annotated_query_plus_ref.h5ad containing your query and the reference cells with predicted annotations. | confusion_matrices.pdf which contains the confusion matrices between the consensus_predictions and each individual method. | csv files containing the metrics for each confusion matrix. | . from annotation import annotate_data annotate_data(adata, methods, save_folder, pretrained_scvi_path=pretrained_scvi_path, pretrained_scanvi_path=pretrained_scanvi_path) . Integrating data with bbknn. Classifying with knn on bbknn distances. . /usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py:168: EfficiencyWarning: Precomputed sparse input was not sorted by data. EfficiencyWarning) /content/annotation.py:706: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred . Saved knn on bbknn results to adata.obs[&#34;knn_on_bbknn_pred&#34;] . ... storing &#39;knn_on_bbknn_pred&#39; as categorical ... storing &#39;knn_on_bbknn_pred&#39; as categorical . Running scVI. . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Training scvi offline. Epoch 77/77: 100%|██████████| 77/77 [04:00&lt;00:00, 3.13s/it, loss=778, v_num=1] Classifying with knn on scVI latent space. Training knn on scvi latent space. Using latent space in adata.obsm[&#34;X_scvi_offline&#34;] . /content/annotation.py:910: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred ... storing &#39;knn_on_scvi_offline_pred&#39; as categorical ... storing &#39;knn_on_scvi_offline_pred&#39; as categorical . Running scANVI. INFO Training for 77 epochs. . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Epoch 77/77: 100%|██████████| 77/77 [09:18&lt;00:00, 7.25s/it, loss=934, v_num=1] . ... storing &#39;scanvi_offline_pred&#39; as categorical ... storing &#39;scanvi_offline_pred&#39; as categorical . Classifying with SVM. . /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. &#34;the number of iterations.&#34;, ConvergenceWarning) /content/annotation.py:819: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_idx] = svm_pred ... storing &#39;svm_pred&#39; as categorical ... storing &#39;svm_pred&#39; as categorical . Classifying with random forest. Training random forest classifier with 2837 cells . /content/annotation.py:730: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_idx] = rf_pred ... storing &#39;rf_pred&#39; as categorical ... storing &#39;rf_pred&#39; as categorical . Running OnClass. init OnClass 29434 4000 35 2353 Training cost after epoch 1: loss:18.195199 acc: 0.848 auc: 0.971 auprc: 0.747 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 2: loss:6.472742 acc: 0.861 auc: 0.986 auprc: 0.784 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 3: loss:7.418795 acc: 0.891 auc: 0.990 auprc: 0.848 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 4: loss:6.403556 acc: 0.913 auc: 0.992 auprc: 0.876 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 5: loss:6.138159 acc: 0.906 auc: 0.993 auprc: 0.891 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 6: loss:3.145052 acc: 0.911 auc: 0.995 auprc: 0.905 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 7: loss:2.841035 acc: 0.937 auc: 0.996 auprc: 0.934 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 8: loss:3.699444 acc: 0.923 auc: 0.996 auprc: 0.941 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 9: loss:3.115471 acc: 0.922 auc: 0.994 auprc: 0.916 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 10: loss:2.733034 acc: 0.925 auc: 0.996 auprc: 0.927 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 11: loss:3.285794 acc: 0.929 auc: 0.996 auprc: 0.932 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 12: loss:2.393076 acc: 0.940 auc: 0.996 auprc: 0.920 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 13: loss:3.487159 acc: 0.945 auc: 0.997 auprc: 0.937 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 14: loss:3.418227 acc: 0.940 auc: 0.997 auprc: 0.934 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 15: loss:1.947167 acc: 0.949 auc: 0.998 auprc: 0.943 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 16: loss:1.995989 acc: 0.927 auc: 0.996 auprc: 0.947 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 17: loss:3.059286 acc: 0.940 auc: 0.996 auprc: 0.953 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 18: loss:1.990470 acc: 0.950 auc: 0.997 auprc: 0.960 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 19: loss:1.754694 acc: 0.952 auc: 0.998 auprc: 0.962 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) . Training cost after epoch 20: loss:1.563520 acc: 0.955 auc: 0.998 auprc: 0.970 . /usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1114: RuntimeWarning: All-NaN slice encountered overwrite_input=overwrite_input) Trying to set attribute `.obs` of view, copying. /content/annotation.py:786: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test_adata.obs[save_key][i : i + shard_size] = pred_label_str /content/annotation.py:786: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy test_adata.obs[save_key][i : i + shard_size] = pred_label_str /content/annotation.py:794: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[save_key][test_adata.obs_names] = test_adata.obs[save_key] /usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy iloc._setitem_with_indexer(indexer, value) ... storing &#39;onclass_pred&#39; as categorical ... storing &#39;onclass_pred&#39; as categorical . Running scanorama. Found 4000 genes among all datasets [[0. 0.41865767 0.74522293 0.25761952 0.27251995 0.6864704 ] [0. 0. 0.52866242 0.29192949 0.2668187 0.1584653 ] [0. 0. 0. 0.23248408 0.28620296 0.60350318] [0. 0. 0. 0. 0.6704675 0.19555744] [0. 0. 0. 0. 0. 0.42189282] [0. 0. 0. 0. 0. 0. ]] Processing datasets (0, 2) Processing datasets (0, 5) Processing datasets (3, 4) Processing datasets (2, 5) Processing datasets (1, 2) Processing datasets (4, 5) Processing datasets (0, 1) Processing datasets (1, 3) Processing datasets (2, 4) Processing datasets (0, 4) Processing datasets (1, 4) Processing datasets (0, 3) Processing datasets (2, 3) Processing datasets (3, 5) Processing datasets (1, 5) Computing umap on scanorama Classifying with knn on scanorama latent space. Running knn on scanorama . /content/annotation.py:938: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy adata.obs[result_key][query_idx] = knn_pred ... storing &#39;knn_on_scanorama_pred&#39; as categorical ... storing &#39;knn_on_scanorama_pred&#39; as categorical ... storing &#39;consensus_prediction&#39; as categorical ... storing &#39;consensus_percentage&#39; as categorical ... storing &#39;consensus_prediction&#39; as categorical ... storing &#39;consensus_percentage&#39; as categorical . Step 6 Generate Statistics and Figures . No user action required. . import pandas as pd import matplotlib.pyplot as plt results_file = os.path.join(save_folder,&#39;annotated_query_plus_ref.h5ad&#39;) results = anndata.read(results_file) . from annotation import make_agreement_plots all_prediction_keys = [ &quot;knn_on_bbknn_pred&quot;, &quot;knn_on_scvi_online_pred&quot;, &quot;knn_on_scvi_offline_pred&quot;, &quot;scanvi_online_pred&quot;, &quot;scanvi_offline_pred&quot;, &quot;svm_pred&quot;, &quot;rf_pred&quot;, &quot;onclass_pred&quot;, &quot;knn_on_scanorama_pred&quot;, ] obs_keys = adata.obs.keys() pred_keys = [key for key in obs_keys if key in all_prediction_keys] make_agreement_plots(results, methods=pred_keys, save_folder=save_folder) is_query = results.obs._dataset == &quot;query&quot; methods = [x for x in results.obs.columns if x.endswith(&quot;_pred&quot;)] labels = results.obs.consensus_prediction.astype(str) labels[~is_query] = results[~is_query].obs._labels_annotation.astype(str) celltypes = np.unique(labels) latent_methods = results.obsm.keys() . Making confusion matrix for knn_on_bbknn_pred Making confusion matrix for knn_on_scvi_offline_pred Making confusion matrix for scanvi_offline_pred Making confusion matrix for svm_pred Making confusion matrix for rf_pred Making confusion matrix for onclass_pred Making confusion matrix for knn_on_scanorama_pred . Distribution of consensus percentage . The more the algorithms agree with each other, the better the annotation has worked . agreement_counts = pd.DataFrame( np.unique(results[is_query].obs[&quot;consensus_percentage&quot;], return_counts=True) ).T agreement_counts.columns = [&quot;Percent Agreement&quot;, &quot;Count&quot;] agreement_counts.plot.bar( x=&quot;Percent Agreement&quot;, y=&quot;Count&quot;, legend=False, figsize=(4, 3) ) plt.ylabel(&quot;Frequency&quot;) plt.xlabel(&quot;Percent of Algorithms Agreeing with Majority Vote&quot;) figpath = os.path.join(save_folder, &quot;Concensus_Percentage_barplot.pdf&quot;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) . Per cell type agreement . Some cell types can be better predicted than others, and we can highlight the celltypes that are poorly predicted by looking at the per celltype agreement. The cell types are separated by the concensus predictions. . mean_agreement = [ np.mean(results[is_query &amp; (labels == x)].obs[&quot;consensus_percentage&quot;].astype(float)) for x in celltypes ] mean_agreement = pd.DataFrame([mean_agreement], index=[&quot;agreement&quot;]).T mean_agreement.index = celltypes mean_agreement = mean_agreement.sort_values(&quot;agreement&quot;, ascending=True) mean_agreement.plot.bar(y=&quot;agreement&quot;, figsize=(15, 2), legend=False) plt.ylabel(&quot;Mean Agreement&quot;) plt.xticks(rotation=290, ha=&quot;left&quot;) figpath = os.path.join(save_folder, &quot;percelltype_agreement_barplot.pdf&quot;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) . Cell type proportion plot . prop = pd.DataFrame(index=celltypes, columns=[&quot;ref&quot;, &quot;query&quot;]) for x in celltypes: prop.loc[x, &quot;query&quot;] = np.sum(labels[is_query] == x) prop.loc[x, &quot;ref&quot;] = np.sum(labels[~is_query] == x) . prop.loc[mean_agreement.index].plot(kind=&#39;bar&#39;, figsize=(len(celltypes)*0.5,4),logy=True) plt.legend(bbox_to_anchor=(1, 0.9)) plt.ylabel(&#39;log Celltype Abundance&#39;) plt.tight_layout() figpath = os.path.join(save_folder, &#39;celltype_prop_barplot.pdf&#39;) plt.savefig(figpath, bbox_inches=&quot;tight&quot;) plt.show() plt.close() .",
            "url": "https://vikkki.github.io/vikkki_blog/python/jupyter/singlecell/annotation/2022/02/09/Automated_Cell_Annotation.html",
            "relUrl": "/python/jupyter/singlecell/annotation/2022/02/09/Automated_Cell_Annotation.html",
            "date": " • Feb 9, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://vikkki.github.io/vikkki_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://vikkki.github.io/vikkki_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Graduate student at the USC, Transnational Bioinformatics project, and a gardener. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://vikkki.github.io/vikkki_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://vikkki.github.io/vikkki_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}